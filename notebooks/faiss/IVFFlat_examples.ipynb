{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# IVFFlat Algorithm Examples in FAISS\n",
        "\n",
        "This notebook demonstrates the IVFFlat (Inverted File with Flat quantizer) algorithm in FAISS with various parameter combinations.\n",
        "\n",
        "## Key Parameters\n",
        "\n",
        "- **nlist**: Number of clusters (Voronoi cells) in the inverted file index. Higher nlist = finer partitioning, faster search but longer training.\n",
        "- **nprobe**: Number of clusters to visit during search. Higher nprobe = better recall but slower search.\n",
        "\n",
        "We'll explore how these parameters affect:\n",
        "1. Search recall (accuracy)\n",
        "2. Search time\n",
        "3. Training time\n",
        "4. Memory usage\n",
        "\n",
        "## How IVFFlat Works\n",
        "\n",
        "1. **Training**: K-means clustering partitions the vector space into `nlist` clusters (Voronoi cells)\n",
        "2. **Adding**: Each vector is assigned to its nearest cluster centroid and stored in that cluster's inverted list\n",
        "3. **Searching**: Query vector is compared to cluster centroids, then `nprobe` nearest clusters are searched exhaustively"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import faiss\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Plotting style\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Dataset Generation\n",
        "\n",
        "We'll create a synthetic dataset for our experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_dataset(nb, nq, d):\n",
        "    \"\"\"\n",
        "    Generate random database and query vectors.\n",
        "    \n",
        "    Args:\n",
        "        nb: Number of database vectors\n",
        "        nq: Number of query vectors  \n",
        "        d: Vector dimension\n",
        "    \n",
        "    Returns:\n",
        "        xb: Database vectors (nb x d)\n",
        "        xq: Query vectors (nq x d)\n",
        "    \"\"\"\n",
        "    xb = np.random.random((nb, d)).astype('float32')\n",
        "    xq = np.random.random((nq, d)).astype('float32')\n",
        "    return xb, xq\n",
        "\n",
        "# Dataset parameters\n",
        "nb = 100000   # Database size\n",
        "nq = 1000     # Number of queries\n",
        "d = 128       # Vector dimension\n",
        "k = 10        # Number of nearest neighbors to find\n",
        "\n",
        "print(f\"Generating dataset: {nb:,} database vectors, {nq:,} queries, dimension {d}\")\n",
        "xb, xq = generate_dataset(nb, nq, d)\n",
        "print(f\"Database shape: {xb.shape}, Query shape: {xq.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Ground Truth Computation\n",
        "\n",
        "Compute exact nearest neighbors using brute-force search for recall evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_ground_truth(xb, xq, k):\n",
        "    \"\"\"Compute exact nearest neighbors using IndexFlatL2.\"\"\"\n",
        "    index_flat = faiss.IndexFlatL2(xb.shape[1])\n",
        "    index_flat.add(xb)\n",
        "    distances_gt, labels_gt = index_flat.search(xq, k)\n",
        "    return distances_gt, labels_gt\n",
        "\n",
        "def compute_recall(labels_gt, labels_approx, k):\n",
        "    \"\"\"Compute recall@k: fraction of true neighbors found.\"\"\"\n",
        "    n = labels_gt.shape[0]\n",
        "    recall = 0.0\n",
        "    for i in range(n):\n",
        "        gt_set = set(labels_gt[i, :k])\n",
        "        approx_set = set(labels_approx[i, :k])\n",
        "        recall += len(gt_set & approx_set) / k\n",
        "    return recall / n\n",
        "\n",
        "print(\"Computing ground truth with brute-force search...\")\n",
        "start = time.time()\n",
        "distances_gt, labels_gt = compute_ground_truth(xb, xq, k)\n",
        "gt_time = time.time() - start\n",
        "print(f\"Ground truth computed in {gt_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Helper Functions for IVFFlat Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_ivfflat_index(xb, nlist):\n",
        "    \"\"\"\n",
        "    Build IVFFlat index with given number of clusters.\n",
        "    \n",
        "    Returns:\n",
        "        index: Built IVFFlat index\n",
        "        train_time: Time taken to train (seconds)\n",
        "        add_time: Time taken to add vectors (seconds)\n",
        "    \"\"\"\n",
        "    d = xb.shape[1]\n",
        "    \n",
        "    # Create quantizer (flat index for centroids)\n",
        "    quantizer = faiss.IndexFlatL2(d)\n",
        "    \n",
        "    # Create IVFFlat index\n",
        "    index = faiss.IndexIVFFlat(quantizer, d, nlist)\n",
        "    \n",
        "    # Train the index (learn cluster centroids)\n",
        "    start = time.time()\n",
        "    index.train(xb)\n",
        "    train_time = time.time() - start\n",
        "    \n",
        "    # Add vectors to the index\n",
        "    start = time.time()\n",
        "    index.add(xb)\n",
        "    add_time = time.time() - start\n",
        "    \n",
        "    return index, train_time, add_time\n",
        "\n",
        "def search_ivfflat_index(index, xq, k, nprobe):\n",
        "    \"\"\"\n",
        "    Search IVFFlat index with given nprobe.\n",
        "    \n",
        "    Returns:\n",
        "        distances: Distance array\n",
        "        labels: Label array\n",
        "        search_time: Time taken to search (seconds)\n",
        "    \"\"\"\n",
        "    index.nprobe = nprobe\n",
        "    \n",
        "    start = time.time()\n",
        "    distances, labels = index.search(xq, k)\n",
        "    search_time = time.time() - start\n",
        "    \n",
        "    return distances, labels, search_time\n",
        "\n",
        "def estimate_memory_usage(index, d):\n",
        "    \"\"\"Estimate memory usage of IVFFlat index in MB.\"\"\"\n",
        "    # Vector storage: ntotal * d * 4 bytes (vectors stored in full)\n",
        "    vector_mem = index.ntotal * d * 4\n",
        "    \n",
        "    # Centroid storage: nlist * d * 4 bytes\n",
        "    centroid_mem = index.nlist * d * 4\n",
        "    \n",
        "    # ID storage: ntotal * 8 bytes (int64 IDs)\n",
        "    id_mem = index.ntotal * 8\n",
        "    \n",
        "    total_mb = (vector_mem + centroid_mem + id_mem) / (1024 * 1024)\n",
        "    return total_mb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Experiment 1: Effect of nlist (Number of Clusters)\n",
        "\n",
        "nlist controls the number of Voronoi cells. Higher nlist means:\n",
        "- Finer partitioning of the vector space\n",
        "- Faster search (fewer vectors per cluster to scan)\n",
        "- Longer training time (more k-means iterations)\n",
        "- Need more training data (rule of thumb: 30-256 × nlist vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test different values of nlist\n",
        "nlist_values = [16, 32, 64, 128, 256, 512, 1024]\n",
        "nprobe_fixed = 10\n",
        "\n",
        "results_nlist = []\n",
        "\n",
        "print(\"Experiment 1: Varying nlist\")\n",
        "print(f\"Fixed nprobe={nprobe_fixed}\\n\")\n",
        "print(f\"{'nlist':>8} {'Train(s)':>10} {'Add(s)':>8} {'Search(ms)':>12} {'Recall':>10} {'Vecs/List':>12}\")\n",
        "print(\"-\" * 66)\n",
        "\n",
        "for nlist in nlist_values:\n",
        "    # Build index\n",
        "    index, train_time, add_time = build_ivfflat_index(xb, nlist)\n",
        "    \n",
        "    # Search\n",
        "    distances, labels, search_time = search_ivfflat_index(index, xq, k, nprobe_fixed)\n",
        "    \n",
        "    # Compute metrics\n",
        "    recall = compute_recall(labels_gt, labels, k)\n",
        "    vecs_per_list = nb / nlist\n",
        "    \n",
        "    results_nlist.append({\n",
        "        'nlist': nlist,\n",
        "        'train_time': train_time,\n",
        "        'add_time': add_time,\n",
        "        'search_time_ms': search_time * 1000,\n",
        "        'recall': recall,\n",
        "        'vecs_per_list': vecs_per_list\n",
        "    })\n",
        "    \n",
        "    print(f\"{nlist:>8} {train_time:>10.2f} {add_time:>8.2f} {search_time*1000:>12.2f} {recall:>10.4f} {vecs_per_list:>12.0f}\")\n",
        "\n",
        "df_nlist = pd.DataFrame(results_nlist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize effect of nlist\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Recall vs nlist\n",
        "ax1 = axes[0, 0]\n",
        "ax1.plot(df_nlist['nlist'], df_nlist['recall'], 'o-', linewidth=2, markersize=8, color='#2ecc71')\n",
        "ax1.set_xlabel('nlist (number of clusters)')\n",
        "ax1.set_ylabel('Recall@10')\n",
        "ax1.set_title('Recall vs nlist')\n",
        "ax1.set_xscale('log', base=2)\n",
        "ax1.set_ylim([0, 1.02])\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Search time vs nlist\n",
        "ax2 = axes[0, 1]\n",
        "ax2.plot(df_nlist['nlist'], df_nlist['search_time_ms'], 'o-', linewidth=2, markersize=8, color='#e74c3c')\n",
        "ax2.set_xlabel('nlist (number of clusters)')\n",
        "ax2.set_ylabel('Search Time (ms)')\n",
        "ax2.set_title('Search Time vs nlist')\n",
        "ax2.set_xscale('log', base=2)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Train time vs nlist\n",
        "ax3 = axes[1, 0]\n",
        "ax3.plot(df_nlist['nlist'], df_nlist['train_time'], 'o-', linewidth=2, markersize=8, color='#3498db')\n",
        "ax3.set_xlabel('nlist (number of clusters)')\n",
        "ax3.set_ylabel('Training Time (s)')\n",
        "ax3.set_title('Training Time vs nlist')\n",
        "ax3.set_xscale('log', base=2)\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Vectors per list vs nlist\n",
        "ax4 = axes[1, 1]\n",
        "ax4.plot(df_nlist['nlist'], df_nlist['vecs_per_list'], 'o-', linewidth=2, markersize=8, color='#9b59b6')\n",
        "ax4.set_xlabel('nlist (number of clusters)')\n",
        "ax4.set_ylabel('Vectors per Inverted List')\n",
        "ax4.set_title('Average Cluster Size vs nlist')\n",
        "ax4.set_xscale('log', base=2)\n",
        "ax4.set_yscale('log')\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle(f'Effect of nlist (nprobe={nprobe_fixed})', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Experiment 2: Effect of nprobe (Search Probes)\n",
        "\n",
        "nprobe controls how many clusters are searched during query. This is the main recall/speed trade-off:\n",
        "- Higher nprobe = better recall but slower search\n",
        "- Can be adjusted at query time without rebuilding the index\n",
        "- Setting nprobe = nlist gives exact search (but defeats the purpose of IVF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test different values of nprobe\n",
        "nprobe_values = [1, 2, 4, 8, 16, 32, 64, 128, 256]\n",
        "nlist_fixed = 256\n",
        "\n",
        "# Build index once\n",
        "print(f\"Building index with nlist={nlist_fixed}...\")\n",
        "index, train_time, add_time = build_ivfflat_index(xb, nlist_fixed)\n",
        "print(f\"Index trained in {train_time:.2f}s, vectors added in {add_time:.2f}s\\n\")\n",
        "\n",
        "results_nprobe = []\n",
        "\n",
        "print(\"Experiment 2: Varying nprobe\")\n",
        "print(f\"{'nprobe':>8} {'Search(ms)':>12} {'Recall':>10} {'QPS':>12} {'% Lists':>10}\")\n",
        "print(\"-\" * 56)\n",
        "\n",
        "for nprobe in nprobe_values:\n",
        "    if nprobe > nlist_fixed:\n",
        "        continue\n",
        "        \n",
        "    # Search\n",
        "    distances, labels, search_time = search_ivfflat_index(index, xq, k, nprobe)\n",
        "    \n",
        "    # Compute metrics\n",
        "    recall = compute_recall(labels_gt, labels, k)\n",
        "    qps = nq / search_time\n",
        "    pct_lists = (nprobe / nlist_fixed) * 100\n",
        "    \n",
        "    results_nprobe.append({\n",
        "        'nprobe': nprobe,\n",
        "        'search_time_ms': search_time * 1000,\n",
        "        'recall': recall,\n",
        "        'qps': qps,\n",
        "        'pct_lists': pct_lists\n",
        "    })\n",
        "    \n",
        "    print(f\"{nprobe:>8} {search_time*1000:>12.2f} {recall:>10.4f} {qps:>12.0f} {pct_lists:>10.1f}%\")\n",
        "\n",
        "df_nprobe = pd.DataFrame(results_nprobe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize effect of nprobe\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Recall vs nprobe\n",
        "ax1 = axes[0]\n",
        "ax1.plot(df_nprobe['nprobe'], df_nprobe['recall'], 'o-', linewidth=2, markersize=8, color='#2ecc71')\n",
        "ax1.set_xlabel('nprobe')\n",
        "ax1.set_ylabel('Recall@10')\n",
        "ax1.set_title('Recall vs nprobe')\n",
        "ax1.set_xscale('log', base=2)\n",
        "ax1.set_ylim([0, 1.02])\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Search time vs nprobe\n",
        "ax2 = axes[1]\n",
        "ax2.plot(df_nprobe['nprobe'], df_nprobe['search_time_ms'], 'o-', linewidth=2, markersize=8, color='#e74c3c')\n",
        "ax2.set_xlabel('nprobe')\n",
        "ax2.set_ylabel('Search Time (ms)')\n",
        "ax2.set_title('Search Time vs nprobe')\n",
        "ax2.set_xscale('log', base=2)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# QPS vs nprobe\n",
        "ax3 = axes[2]\n",
        "ax3.plot(df_nprobe['nprobe'], df_nprobe['qps'], 'o-', linewidth=2, markersize=8, color='#3498db')\n",
        "ax3.set_xlabel('nprobe')\n",
        "ax3.set_ylabel('Queries Per Second')\n",
        "ax3.set_title('Throughput vs nprobe')\n",
        "ax3.set_xscale('log', base=2)\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle(f'Effect of nprobe (nlist={nlist_fixed})', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Recall-QPS trade-off curve (Pareto frontier)\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "ax.plot(df_nprobe['recall'], df_nprobe['qps'], 'o-', linewidth=2, markersize=10, color='#8e44ad')\n",
        "\n",
        "# Annotate points with nprobe values\n",
        "for i, row in df_nprobe.iterrows():\n",
        "    ax.annotate(f\"nprobe={int(row['nprobe'])}\", \n",
        "                (row['recall'], row['qps']),\n",
        "                textcoords=\"offset points\", \n",
        "                xytext=(5, 5), \n",
        "                fontsize=9)\n",
        "\n",
        "ax.set_xlabel('Recall@10', fontsize=12)\n",
        "ax.set_ylabel('Queries Per Second (QPS)', fontsize=12)\n",
        "ax.set_title('Recall vs Throughput Trade-off\\n(Pareto Frontier for nprobe)', fontsize=14, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Experiment 3: Combined Parameter Grid Search\n",
        "\n",
        "Let's explore the combined effect of nlist and nprobe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Grid search over nlist and nprobe\n",
        "nlist_grid = [64, 128, 256, 512]\n",
        "nprobe_grid = [1, 4, 8, 16, 32, 64]\n",
        "\n",
        "# Pre-build indexes for each nlist\n",
        "indexes = {}\n",
        "print(\"Building indexes...\")\n",
        "for nlist in nlist_grid:\n",
        "    index, train_time, add_time = build_ivfflat_index(xb, nlist)\n",
        "    indexes[nlist] = index\n",
        "    print(f\"  nlist={nlist}: trained in {train_time:.2f}s, added in {add_time:.2f}s\")\n",
        "\n",
        "# Run grid search\n",
        "grid_results = []\n",
        "\n",
        "print(\"\\nRunning grid search...\")\n",
        "for nlist in nlist_grid:\n",
        "    index = indexes[nlist]\n",
        "    for nprobe in nprobe_grid:\n",
        "        if nprobe > nlist:\n",
        "            continue\n",
        "            \n",
        "        distances, labels, search_time = search_ivfflat_index(index, xq, k, nprobe)\n",
        "        recall = compute_recall(labels_gt, labels, k)\n",
        "        qps = nq / search_time\n",
        "        \n",
        "        grid_results.append({\n",
        "            'nlist': nlist,\n",
        "            'nprobe': nprobe,\n",
        "            'recall': recall,\n",
        "            'search_time_ms': search_time * 1000,\n",
        "            'qps': qps,\n",
        "            'nprobe_ratio': nprobe / nlist\n",
        "        })\n",
        "\n",
        "df_grid = pd.DataFrame(grid_results)\n",
        "print(\"\\nGrid search complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize grid results\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "colors = plt.cm.viridis(np.linspace(0, 1, len(nlist_grid)))\n",
        "\n",
        "# Recall curves for different nlist\n",
        "ax1 = axes[0]\n",
        "for i, nlist in enumerate(nlist_grid):\n",
        "    data = df_grid[df_grid['nlist'] == nlist]\n",
        "    ax1.plot(data['nprobe'], data['recall'], 'o-', \n",
        "             linewidth=2, markersize=8, color=colors[i], label=f'nlist={nlist}')\n",
        "ax1.set_xlabel('nprobe')\n",
        "ax1.set_ylabel('Recall@10')\n",
        "ax1.set_title('Recall vs nprobe for Different nlist')\n",
        "ax1.set_xscale('log', base=2)\n",
        "ax1.set_ylim([0, 1.02])\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Recall vs QPS for different nlist\n",
        "ax2 = axes[1]\n",
        "for i, nlist in enumerate(nlist_grid):\n",
        "    data = df_grid[df_grid['nlist'] == nlist]\n",
        "    ax2.plot(data['recall'], data['qps'], 'o-', \n",
        "             linewidth=2, markersize=8, color=colors[i], label=f'nlist={nlist}')\n",
        "ax2.set_xlabel('Recall@10')\n",
        "ax2.set_ylabel('Queries Per Second')\n",
        "ax2.set_title('Recall-Throughput Trade-off')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('Combined Effect of nlist and nprobe', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create heatmaps for a clearer view of parameter interactions\n",
        "# We need to handle the fact that not all nprobe values exist for all nlist values\n",
        "pivot_data = df_grid.pivot_table(index='nlist', columns='nprobe', values='recall', aggfunc='first')\n",
        "pivot_qps = df_grid.pivot_table(index='nlist', columns='nprobe', values='qps', aggfunc='first')\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Recall heatmap\n",
        "im1 = axes[0].imshow(pivot_data.values, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1.0)\n",
        "axes[0].set_xticks(range(len(pivot_data.columns)))\n",
        "axes[0].set_xticklabels(pivot_data.columns.astype(int))\n",
        "axes[0].set_yticks(range(len(pivot_data.index)))\n",
        "axes[0].set_yticklabels(pivot_data.index.astype(int))\n",
        "axes[0].set_xlabel('nprobe')\n",
        "axes[0].set_ylabel('nlist')\n",
        "axes[0].set_title('Recall@10 Heatmap')\n",
        "\n",
        "# Add text annotations\n",
        "for i in range(len(pivot_data.index)):\n",
        "    for j in range(len(pivot_data.columns)):\n",
        "        val = pivot_data.values[i, j]\n",
        "        if not np.isnan(val):\n",
        "            axes[0].text(j, i, f'{val:.3f}', ha='center', va='center', color='black', fontsize=9)\n",
        "\n",
        "fig.colorbar(im1, ax=axes[0])\n",
        "\n",
        "# QPS heatmap\n",
        "im2 = axes[1].imshow(pivot_qps.values, cmap='YlOrRd_r', aspect='auto')\n",
        "axes[1].set_xticks(range(len(pivot_qps.columns)))\n",
        "axes[1].set_xticklabels(pivot_qps.columns.astype(int))\n",
        "axes[1].set_yticks(range(len(pivot_qps.index)))\n",
        "axes[1].set_yticklabels(pivot_qps.index.astype(int))\n",
        "axes[1].set_xlabel('nprobe')\n",
        "axes[1].set_ylabel('nlist')\n",
        "axes[1].set_title('QPS Heatmap')\n",
        "\n",
        "# Add text annotations\n",
        "for i in range(len(pivot_qps.index)):\n",
        "    for j in range(len(pivot_qps.columns)):\n",
        "        val = pivot_qps.values[i, j]\n",
        "        if not np.isnan(val):\n",
        "            axes[1].text(j, i, f'{val:.0f}', ha='center', va='center', color='black', fontsize=9)\n",
        "\n",
        "fig.colorbar(im2, ax=axes[1])\n",
        "\n",
        "plt.suptitle('Parameter Grid Search Results', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Experiment 4: nprobe as Percentage of nlist\n",
        "\n",
        "A useful way to think about nprobe is as a percentage of nlist. Let's see if using the same ratio gives consistent recall across different nlist values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with nprobe as percentage of nlist\n",
        "nlist_test = [64, 128, 256, 512, 1024]\n",
        "pct_values = [1, 2, 5, 10, 25, 50]  # percentage of nlist to probe\n",
        "\n",
        "pct_results = []\n",
        "\n",
        "print(\"Experiment 4: nprobe as percentage of nlist\\n\")\n",
        "print(f\"{'nlist':>8} {'%':>6} {'nprobe':>8} {'Recall':>10} {'Search(ms)':>12}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "for nlist in nlist_test:\n",
        "    index, _, _ = build_ivfflat_index(xb, nlist)\n",
        "    \n",
        "    for pct in pct_values:\n",
        "        nprobe = max(1, int(nlist * pct / 100))\n",
        "        \n",
        "        distances, labels, search_time = search_ivfflat_index(index, xq, k, nprobe)\n",
        "        recall = compute_recall(labels_gt, labels, k)\n",
        "        \n",
        "        pct_results.append({\n",
        "            'nlist': nlist,\n",
        "            'pct': pct,\n",
        "            'nprobe': nprobe,\n",
        "            'recall': recall,\n",
        "            'search_time_ms': search_time * 1000\n",
        "        })\n",
        "        \n",
        "        print(f\"{nlist:>8} {pct:>6}% {nprobe:>8} {recall:>10.4f} {search_time*1000:>12.2f}\")\n",
        "    print()\n",
        "\n",
        "df_pct = pd.DataFrame(pct_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize recall vs percentage of nlist probed\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "colors = plt.cm.plasma(np.linspace(0, 0.8, len(nlist_test)))\n",
        "\n",
        "# Recall vs percentage\n",
        "ax1 = axes[0]\n",
        "for i, nlist in enumerate(nlist_test):\n",
        "    data = df_pct[df_pct['nlist'] == nlist]\n",
        "    ax1.plot(data['pct'], data['recall'], 'o-', \n",
        "             linewidth=2, markersize=8, color=colors[i], label=f'nlist={nlist}')\n",
        "ax1.set_xlabel('Percentage of nlist probed (%)')\n",
        "ax1.set_ylabel('Recall@10')\n",
        "ax1.set_title('Recall vs % of Clusters Probed')\n",
        "ax1.set_ylim([0, 1.02])\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Search time vs percentage\n",
        "ax2 = axes[1]\n",
        "for i, nlist in enumerate(nlist_test):\n",
        "    data = df_pct[df_pct['nlist'] == nlist]\n",
        "    ax2.plot(data['pct'], data['search_time_ms'], 'o-', \n",
        "             linewidth=2, markersize=8, color=colors[i], label=f'nlist={nlist}')\n",
        "ax2.set_xlabel('Percentage of nlist probed (%)')\n",
        "ax2.set_ylabel('Search Time (ms)')\n",
        "ax2.set_title('Search Time vs % of Clusters Probed')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('Same Probe Ratio Across Different nlist Values', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Experiment 5: Comparison with Brute Force\n",
        "\n",
        "Let's compare IVFFlat performance against brute-force search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Brute force baseline\n",
        "print(\"Comparing IVFFlat with Brute Force (IndexFlatL2)\\n\")\n",
        "\n",
        "# Build brute force index\n",
        "index_flat = faiss.IndexFlatL2(d)\n",
        "start = time.time()\n",
        "index_flat.add(xb)\n",
        "flat_add_time = time.time() - start\n",
        "\n",
        "# Search with brute force\n",
        "start = time.time()\n",
        "D_flat, I_flat = index_flat.search(xq, k)\n",
        "flat_search_time = time.time() - start\n",
        "\n",
        "flat_qps = nq / flat_search_time\n",
        "\n",
        "print(f\"IndexFlatL2 (Brute Force):\")\n",
        "print(f\"  Add time: {flat_add_time:.3f}s\")\n",
        "print(f\"  Search time: {flat_search_time*1000:.2f}ms\")\n",
        "print(f\"  QPS: {flat_qps:.0f}\")\n",
        "print(f\"  Recall: 1.0000 (exact)\")\n",
        "\n",
        "# IVFFlat with good configuration\n",
        "ivf_config = {'nlist': 256, 'nprobe': 16}\n",
        "index_ivf, ivf_train_time, ivf_add_time = build_ivfflat_index(xb, ivf_config['nlist'])\n",
        "D_ivf, I_ivf, ivf_search_time = search_ivfflat_index(index_ivf, xq, k, ivf_config['nprobe'])\n",
        "ivf_recall = compute_recall(I_flat, I_ivf, k)\n",
        "ivf_qps = nq / ivf_search_time\n",
        "\n",
        "print(f\"\\nIndexIVFFlat (nlist={ivf_config['nlist']}, nprobe={ivf_config['nprobe']}):\")\n",
        "print(f\"  Train time: {ivf_train_time:.3f}s\")\n",
        "print(f\"  Add time: {ivf_add_time:.3f}s\")\n",
        "print(f\"  Search time: {ivf_search_time*1000:.2f}ms\")\n",
        "print(f\"  QPS: {ivf_qps:.0f}\")\n",
        "print(f\"  Recall: {ivf_recall:.4f}\")\n",
        "\n",
        "print(f\"\\nSpeedup: {ivf_qps/flat_qps:.1f}x faster at {ivf_recall*100:.1f}% recall\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bar chart comparison\n",
        "fig, axes = plt.subplots(1, 3, figsize=(14, 5))\n",
        "\n",
        "methods = ['Brute Force', f'IVFFlat\\n(nlist={ivf_config[\"nlist\"]})']\n",
        "colors = ['#3498db', '#2ecc71']\n",
        "\n",
        "# Build/Train+Add time\n",
        "build_times = [flat_add_time, ivf_train_time + ivf_add_time]\n",
        "axes[0].bar(methods, build_times, color=colors, edgecolor='black', linewidth=1.5)\n",
        "axes[0].set_ylabel('Build Time (s)')\n",
        "axes[0].set_title('Build Time Comparison\\n(Train + Add for IVFFlat)')\n",
        "for i, v in enumerate(build_times):\n",
        "    axes[0].text(i, v + 0.02, f'{v:.2f}s', ha='center', fontweight='bold')\n",
        "\n",
        "# QPS\n",
        "qps_values = [flat_qps, ivf_qps]\n",
        "axes[1].bar(methods, qps_values, color=colors, edgecolor='black', linewidth=1.5)\n",
        "axes[1].set_ylabel('Queries Per Second')\n",
        "axes[1].set_title('Search Throughput Comparison')\n",
        "for i, v in enumerate(qps_values):\n",
        "    axes[1].text(i, v + 100, f'{v:.0f}', ha='center', fontweight='bold')\n",
        "\n",
        "# Recall\n",
        "recall_values = [1.0, ivf_recall]\n",
        "axes[2].bar(methods, recall_values, color=colors, edgecolor='black', linewidth=1.5)\n",
        "axes[2].set_ylabel('Recall@10')\n",
        "axes[2].set_title('Recall Comparison')\n",
        "axes[2].set_ylim([0, 1.1])\n",
        "for i, v in enumerate(recall_values):\n",
        "    axes[2].text(i, v + 0.02, f'{v:.4f}', ha='center', fontweight='bold')\n",
        "\n",
        "plt.suptitle('IVFFlat vs Brute Force Comparison', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Experiment 6: Typical Configuration Examples\n",
        "\n",
        "Let's test some commonly recommended configurations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Common configurations based on dataset size\n",
        "# Rule of thumb: nlist ≈ sqrt(n) for balanced performance\n",
        "# For 100K vectors: sqrt(100000) ≈ 316\n",
        "\n",
        "configs = [\n",
        "    {'name': 'Small nlist, low nprobe', 'nlist': 100, 'nprobe': 5},\n",
        "    {'name': 'sqrt(n) rule', 'nlist': 316, 'nprobe': 16},\n",
        "    {'name': 'Larger nlist', 'nlist': 1000, 'nprobe': 50},\n",
        "    {'name': 'High recall', 'nlist': 256, 'nprobe': 64},\n",
        "    {'name': 'Speed optimized', 'nlist': 1024, 'nprobe': 8},\n",
        "]\n",
        "\n",
        "config_results = []\n",
        "\n",
        "print(\"Experiment 6: Common Configuration Examples\\n\")\n",
        "print(f\"{'Config':>25} {'nlist':>8} {'nprobe':>8} {'Train(s)':>10} {'Search(ms)':>12} {'Recall':>8} {'QPS':>8}\")\n",
        "print(\"-\" * 90)\n",
        "\n",
        "for config in configs:\n",
        "    # Build index\n",
        "    index, train_time, add_time = build_ivfflat_index(xb, config['nlist'])\n",
        "    \n",
        "    # Search\n",
        "    distances, labels, search_time = search_ivfflat_index(index, xq, k, config['nprobe'])\n",
        "    \n",
        "    # Compute metrics\n",
        "    recall = compute_recall(labels_gt, labels, k)\n",
        "    qps = nq / search_time\n",
        "    memory = estimate_memory_usage(index, d)\n",
        "    \n",
        "    config_results.append({\n",
        "        'name': config['name'],\n",
        "        'nlist': config['nlist'],\n",
        "        'nprobe': config['nprobe'],\n",
        "        'train_time': train_time,\n",
        "        'search_time_ms': search_time * 1000,\n",
        "        'recall': recall,\n",
        "        'qps': qps,\n",
        "        'memory_mb': memory\n",
        "    })\n",
        "    \n",
        "    print(f\"{config['name']:>25} {config['nlist']:>8} {config['nprobe']:>8} \"\n",
        "          f\"{train_time:>10.2f} {search_time*1000:>12.2f} {recall:>8.4f} {qps:>8.0f}\")\n",
        "\n",
        "df_configs = pd.DataFrame(config_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize common configurations\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "\n",
        "# Scatter plot: recall vs QPS, size based on nlist\n",
        "scatter = ax.scatter(df_configs['recall'], df_configs['qps'],\n",
        "                     s=df_configs['nlist'] / 2,  # Size based on nlist\n",
        "                     c=df_configs['nprobe'],  # Color based on nprobe\n",
        "                     cmap='coolwarm', alpha=0.7, edgecolors='black', linewidth=2)\n",
        "\n",
        "# Add labels\n",
        "for i, row in df_configs.iterrows():\n",
        "    ax.annotate(f\"{row['name']}\\nnlist={row['nlist']}, nprobe={row['nprobe']}\",\n",
        "                (row['recall'], row['qps']),\n",
        "                textcoords=\"offset points\",\n",
        "                xytext=(10, 5),\n",
        "                fontsize=9,\n",
        "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7))\n",
        "\n",
        "ax.set_xlabel('Recall@10', fontsize=12)\n",
        "ax.set_ylabel('Queries Per Second', fontsize=12)\n",
        "ax.set_title('Common IVFFlat Configurations\\n(Size = nlist, Color = nprobe)', fontsize=14, fontweight='bold')\n",
        "\n",
        "cbar = plt.colorbar(scatter)\n",
        "cbar.set_label('nprobe', fontsize=11)\n",
        "\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Summary and Recommendations\n",
        "\n",
        "Based on our experiments, here are the key findings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"IVFFlat Parameter Tuning Guidelines\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\"\"\n",
        "1. nlist (Number of clusters):\n",
        "   - Rule of thumb: nlist ≈ sqrt(n) where n is database size\n",
        "   - For {nb:,} vectors: sqrt({nb}) ≈ {int(np.sqrt(nb))}\n",
        "   - Higher nlist → Faster search but longer training\n",
        "   - Need sufficient training data: ~30-256 × nlist vectors minimum\n",
        "   - Recommended range: sqrt(n)/4 to 4×sqrt(n)\n",
        "\n",
        "2. nprobe (Search probes):\n",
        "   - This is your main recall/speed trade-off knob\n",
        "   - Higher nprobe → Better recall but slower search\n",
        "   - Can be adjusted at runtime without rebuilding index\n",
        "   - As a percentage: 1-10% of nlist is common for good balance\n",
        "   - For exact search: set nprobe = nlist (defeats purpose of IVF)\n",
        "\n",
        "Common Configurations:\n",
        "---------------------------------------------------\n",
        "| Use Case          | nlist       | nprobe       |\n",
        "|-------------------|-------------|--------------|\n",
        "| Speed optimized   | 4×sqrt(n)   | 1-5% of nlist|\n",
        "| Balanced          | sqrt(n)     | 5-10% of nlist|\n",
        "| High recall       | sqrt(n)/2   | 10-25% of nlist|\n",
        "| Very high recall  | sqrt(n)/4   | 25-50% of nlist|\n",
        "---------------------------------------------------\n",
        "\n",
        "Rule of thumb formulas:\n",
        "  - nlist = sqrt(n) for balanced performance\n",
        "  - nprobe = nlist/16 to nlist/4 for recall 90-99%\n",
        "\"\"\")\n",
        "\n",
        "# Show best configurations from our experiments\n",
        "print(\"\\nBest configurations from our experiments:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Find configurations with >95% recall\n",
        "high_recall = df_grid[df_grid['recall'] > 0.95].sort_values('qps', ascending=False)\n",
        "if len(high_recall) > 0:\n",
        "    best = high_recall.iloc[0]\n",
        "    print(f\"Best for >95% recall: nlist={int(best['nlist'])}, nprobe={int(best['nprobe'])}\")\n",
        "    print(f\"  Recall: {best['recall']:.4f}, QPS: {best['qps']:.0f}\")\n",
        "\n",
        "# Find fastest configuration with >90% recall  \n",
        "fast_good = df_grid[df_grid['recall'] > 0.90].sort_values('qps', ascending=False)\n",
        "if len(fast_good) > 0:\n",
        "    best = fast_good.iloc[0]\n",
        "    print(f\"\\nFastest with >90% recall: nlist={int(best['nlist'])}, nprobe={int(best['nprobe'])}\")\n",
        "    print(f\"  Recall: {best['recall']:.4f}, QPS: {best['qps']:.0f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Interactive Parameter Explorer\n",
        "\n",
        "Use this cell to experiment with your own parameter combinations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_ivfflat_config(nlist, nprobe, xb, xq, labels_gt, k):\n",
        "    \"\"\"\n",
        "    Test a specific IVFFlat configuration and print results.\n",
        "    \"\"\"\n",
        "    print(f\"Testing IVFFlat with nlist={nlist}, nprobe={nprobe}\")\n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    # Build\n",
        "    index, train_time, add_time = build_ivfflat_index(xb, nlist)\n",
        "    print(f\"Training time: {train_time:.2f}s\")\n",
        "    print(f\"Add time: {add_time:.2f}s\")\n",
        "    print(f\"Vectors per cluster: {len(xb) / nlist:.0f}\")\n",
        "    \n",
        "    # Search\n",
        "    distances, labels, search_time = search_ivfflat_index(index, xq, k, nprobe)\n",
        "    print(f\"Search time: {search_time*1000:.2f}ms for {len(xq)} queries\")\n",
        "    \n",
        "    # Metrics\n",
        "    recall = compute_recall(labels_gt, labels, k)\n",
        "    qps = len(xq) / search_time\n",
        "    memory = estimate_memory_usage(index, xb.shape[1])\n",
        "    \n",
        "    print(f\"Recall@{k}: {recall:.4f}\")\n",
        "    print(f\"QPS: {qps:.0f}\")\n",
        "    print(f\"Estimated memory: {memory:.1f} MB\")\n",
        "    print(f\"nprobe/nlist ratio: {nprobe/nlist*100:.1f}%\")\n",
        "    \n",
        "    return index, recall, qps\n",
        "\n",
        "# Example: Try your own configuration!\n",
        "# Modify these parameters and run the cell\n",
        "my_nlist = 200\n",
        "my_nprobe = 20\n",
        "\n",
        "test_ivfflat_config(my_nlist, my_nprobe, xb, xq, labels_gt, k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Bonus: Using index_factory String\n",
        "\n",
        "FAISS provides a convenient `index_factory` function that creates indexes from a string description."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Using index_factory for IVFFlat\n",
        "print(\"Creating IVFFlat indexes using index_factory:\\n\")\n",
        "\n",
        "# Different index factory strings\n",
        "factory_strings = [\n",
        "    \"IVF100,Flat\",      # 100 clusters, flat storage\n",
        "    \"IVF256,Flat\",      # 256 clusters\n",
        "    \"IVF1024,Flat\",     # 1024 clusters\n",
        "]\n",
        "\n",
        "for factory_string in factory_strings:\n",
        "    print(f\"Factory string: '{factory_string}'\")\n",
        "    \n",
        "    # Create index using factory\n",
        "    index = faiss.index_factory(d, factory_string)\n",
        "    \n",
        "    # Train and add\n",
        "    start = time.time()\n",
        "    index.train(xb)\n",
        "    train_time = time.time() - start\n",
        "    \n",
        "    start = time.time()\n",
        "    index.add(xb)\n",
        "    add_time = time.time() - start\n",
        "    \n",
        "    # Search with nprobe=10\n",
        "    index.nprobe = 10\n",
        "    start = time.time()\n",
        "    D, I = index.search(xq, k)\n",
        "    search_time = time.time() - start\n",
        "    \n",
        "    recall = compute_recall(labels_gt, I, k)\n",
        "    \n",
        "    print(f\"  nlist: {index.nlist}, nprobe: {index.nprobe}\")\n",
        "    print(f\"  Train: {train_time:.2f}s, Add: {add_time:.2f}s, Search: {search_time*1000:.2f}ms\")\n",
        "    print(f\"  Recall@10: {recall:.4f}\")\n",
        "    print()"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
