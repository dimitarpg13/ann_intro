{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# IVFPQ Algorithm Examples in FAISS\n",
        "\n",
        "This notebook demonstrates the IVFPQ (Inverted File with Product Quantization) algorithm in FAISS with various parameter combinations.\n",
        "\n",
        "## Key Parameters\n",
        "\n",
        "### Index Creation Parameters\n",
        "- **nlist**: Number of clusters (Voronoi cells) for the inverted file\n",
        "- **m**: Number of subquantizers for Product Quantization (must divide dimension d)\n",
        "- **nbits**: Number of bits per subquantizer code (typically 8, giving 256 centroids per subspace)\n",
        "\n",
        "### Search-time Parameters  \n",
        "- **nprobe**: Number of clusters to search\n",
        "\n",
        "## How IVFPQ Works\n",
        "\n",
        "1. **Training Phase**:\n",
        "   - K-means clustering creates `nlist` cluster centroids (coarse quantizer)\n",
        "   - Product Quantizer learns `m` codebooks with `2^nbits` centroids each\n",
        "\n",
        "2. **Adding Vectors**:\n",
        "   - Each vector is assigned to its nearest cluster\n",
        "   - The residual (vector - centroid) is encoded using PQ into `m` bytes (with nbits=8)\n",
        "\n",
        "3. **Searching**:\n",
        "   - Query is compared to cluster centroids, selecting `nprobe` nearest clusters\n",
        "   - Distance tables are precomputed for fast PQ distance estimation\n",
        "   - Approximate distances computed using lookup tables\n",
        "\n",
        "## Memory Advantage\n",
        "\n",
        "IVFPQ uses much less memory than IVFFlat:\n",
        "- IVFFlat stores full vectors: `n × d × 4` bytes  \n",
        "- IVFPQ stores PQ codes: `n × m` bytes (with nbits=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import faiss\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Plotting style\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Dataset Generation\n",
        "\n",
        "We'll create a synthetic dataset for our experiments. Note: dimension `d` must be divisible by `m` (number of subquantizers)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_dataset(nb, nq, d):\n",
        "    \"\"\"\n",
        "    Generate random database and query vectors.\n",
        "    \n",
        "    Args:\n",
        "        nb: Number of database vectors\n",
        "        nq: Number of query vectors  \n",
        "        d: Vector dimension\n",
        "    \n",
        "    Returns:\n",
        "        xb: Database vectors (nb x d)\n",
        "        xq: Query vectors (nq x d)\n",
        "    \"\"\"\n",
        "    xb = np.random.random((nb, d)).astype('float32')\n",
        "    xq = np.random.random((nq, d)).astype('float32')\n",
        "    return xb, xq\n",
        "\n",
        "# Dataset parameters\n",
        "# d=128 is divisible by many values: 1, 2, 4, 8, 16, 32, 64, 128\n",
        "nb = 100000   # Database size\n",
        "nq = 1000     # Number of queries\n",
        "d = 128       # Vector dimension (must be divisible by m)\n",
        "k = 10        # Number of nearest neighbors to find\n",
        "\n",
        "print(f\"Generating dataset: {nb:,} database vectors, {nq:,} queries, dimension {d}\")\n",
        "print(f\"Valid m values (must divide {d}): {[i for i in [1,2,4,8,16,32,64] if d % i == 0]}\")\n",
        "xb, xq = generate_dataset(nb, nq, d)\n",
        "print(f\"Database shape: {xb.shape}, Query shape: {xq.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Ground Truth Computation\n",
        "\n",
        "Compute exact nearest neighbors using brute-force search for recall evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_ground_truth(xb, xq, k):\n",
        "    \"\"\"Compute exact nearest neighbors using IndexFlatL2.\"\"\"\n",
        "    index_flat = faiss.IndexFlatL2(xb.shape[1])\n",
        "    index_flat.add(xb)\n",
        "    distances_gt, labels_gt = index_flat.search(xq, k)\n",
        "    return distances_gt, labels_gt\n",
        "\n",
        "def compute_recall(labels_gt, labels_approx, k):\n",
        "    \"\"\"Compute recall@k: fraction of true neighbors found.\"\"\"\n",
        "    n = labels_gt.shape[0]\n",
        "    recall = 0.0\n",
        "    for i in range(n):\n",
        "        gt_set = set(labels_gt[i, :k])\n",
        "        approx_set = set(labels_approx[i, :k])\n",
        "        recall += len(gt_set & approx_set) / k\n",
        "    return recall / n\n",
        "\n",
        "print(\"Computing ground truth with brute-force search...\")\n",
        "start = time.time()\n",
        "distances_gt, labels_gt = compute_ground_truth(xb, xq, k)\n",
        "gt_time = time.time() - start\n",
        "print(f\"Ground truth computed in {gt_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Helper Functions for IVFPQ Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_ivfpq_index(xb, nlist, m, nbits=8):\n",
        "    \"\"\"\n",
        "    Build IVFPQ index with given parameters.\n",
        "    \n",
        "    Args:\n",
        "        xb: Database vectors\n",
        "        nlist: Number of IVF clusters\n",
        "        m: Number of PQ subquantizers\n",
        "        nbits: Bits per subquantizer (default 8)\n",
        "    \n",
        "    Returns:\n",
        "        index: Built IVFPQ index\n",
        "        train_time: Time taken to train (seconds)\n",
        "        add_time: Time taken to add vectors (seconds)\n",
        "    \"\"\"\n",
        "    d = xb.shape[1]\n",
        "    \n",
        "    # Create quantizer (flat index for centroids)\n",
        "    quantizer = faiss.IndexFlatL2(d)\n",
        "    \n",
        "    # Create IVFPQ index\n",
        "    index = faiss.IndexIVFPQ(quantizer, d, nlist, m, nbits)\n",
        "    \n",
        "    # Train the index\n",
        "    start = time.time()\n",
        "    index.train(xb)\n",
        "    train_time = time.time() - start\n",
        "    \n",
        "    # Add vectors\n",
        "    start = time.time()\n",
        "    index.add(xb)\n",
        "    add_time = time.time() - start\n",
        "    \n",
        "    return index, train_time, add_time\n",
        "\n",
        "def search_ivfpq_index(index, xq, k, nprobe):\n",
        "    \"\"\"\n",
        "    Search IVFPQ index with given nprobe.\n",
        "    \n",
        "    Returns:\n",
        "        distances: Distance array\n",
        "        labels: Label array\n",
        "        search_time: Time taken to search (seconds)\n",
        "    \"\"\"\n",
        "    index.nprobe = nprobe\n",
        "    \n",
        "    start = time.time()\n",
        "    distances, labels = index.search(xq, k)\n",
        "    search_time = time.time() - start\n",
        "    \n",
        "    return distances, labels, search_time\n",
        "\n",
        "def estimate_memory_usage_ivfpq(n, d, nlist, m, nbits=8):\n",
        "    \"\"\"Estimate memory usage of IVFPQ index in MB.\"\"\"\n",
        "    # Centroid storage: nlist * d * 4 bytes\n",
        "    centroid_mem = nlist * d * 4\n",
        "    \n",
        "    # PQ codebook: m * 2^nbits * (d/m) * 4 bytes\n",
        "    codebook_mem = m * (2**nbits) * (d // m) * 4\n",
        "    \n",
        "    # PQ codes: n * m * ceil(nbits/8) bytes\n",
        "    bytes_per_code = (nbits + 7) // 8\n",
        "    code_mem = n * m * bytes_per_code\n",
        "    \n",
        "    # ID storage: n * 8 bytes\n",
        "    id_mem = n * 8\n",
        "    \n",
        "    total_mb = (centroid_mem + codebook_mem + code_mem + id_mem) / (1024 * 1024)\n",
        "    return total_mb\n",
        "\n",
        "def estimate_memory_usage_flat(n, d):\n",
        "    \"\"\"Estimate memory usage of IVFFlat for comparison.\"\"\"\n",
        "    return (n * d * 4 + n * 8) / (1024 * 1024)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Experiment 1: Effect of m (Number of Subquantizers)\n",
        "\n",
        "The parameter `m` controls the compression ratio:\n",
        "- Higher m → Better accuracy (more bits to represent each vector)\n",
        "- Lower m → More compression, less memory, but lower recall\n",
        "- `m` must divide the dimension `d`\n",
        "- With nbits=8, each vector is encoded in `m` bytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test different values of m (subquantizers)\n",
        "m_values = [4, 8, 16, 32, 64]  # Must divide d=128\n",
        "nlist_fixed = 256\n",
        "nprobe_fixed = 16\n",
        "nbits_fixed = 8\n",
        "\n",
        "results_m = []\n",
        "\n",
        "print(\"Experiment 1: Varying m (number of subquantizers)\")\n",
        "print(f\"Fixed: nlist={nlist_fixed}, nprobe={nprobe_fixed}, nbits={nbits_fixed}\\n\")\n",
        "print(f\"{'m':>4} {'d/m':>6} {'Bytes/vec':>10} {'Train(s)':>10} {'Search(ms)':>12} {'Recall':>10} {'Mem(MB)':>10}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for m in m_values:\n",
        "    # Build index\n",
        "    index, train_time, add_time = build_ivfpq_index(xb, nlist_fixed, m, nbits_fixed)\n",
        "    \n",
        "    # Search\n",
        "    distances, labels, search_time = search_ivfpq_index(index, xq, k, nprobe_fixed)\n",
        "    \n",
        "    # Compute metrics\n",
        "    recall = compute_recall(labels_gt, labels, k)\n",
        "    memory = estimate_memory_usage_ivfpq(nb, d, nlist_fixed, m, nbits_fixed)\n",
        "    bytes_per_vec = m  # With nbits=8\n",
        "    subvec_dim = d // m\n",
        "    \n",
        "    results_m.append({\n",
        "        'm': m,\n",
        "        'subvec_dim': subvec_dim,\n",
        "        'bytes_per_vec': bytes_per_vec,\n",
        "        'train_time': train_time,\n",
        "        'add_time': add_time,\n",
        "        'search_time_ms': search_time * 1000,\n",
        "        'recall': recall,\n",
        "        'memory_mb': memory\n",
        "    })\n",
        "    \n",
        "    print(f\"{m:>4} {subvec_dim:>6} {bytes_per_vec:>10} {train_time:>10.2f} {search_time*1000:>12.2f} {recall:>10.4f} {memory:>10.1f}\")\n",
        "\n",
        "df_m = pd.DataFrame(results_m)\n",
        "\n",
        "# Compare with IVFFlat memory\n",
        "flat_memory = estimate_memory_usage_flat(nb, d)\n",
        "print(f\"\\nFor comparison, IVFFlat would use: {flat_memory:.1f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize effect of m\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Recall vs m\n",
        "ax1 = axes[0, 0]\n",
        "ax1.plot(df_m['m'], df_m['recall'], 'o-', linewidth=2, markersize=8, color='#2ecc71')\n",
        "ax1.set_xlabel('m (subquantizers)')\n",
        "ax1.set_ylabel('Recall@10')\n",
        "ax1.set_title('Recall vs m')\n",
        "ax1.set_xscale('log', base=2)\n",
        "ax1.set_ylim([0, 1.02])\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Memory vs m (including IVFFlat baseline)\n",
        "ax2 = axes[0, 1]\n",
        "ax2.plot(df_m['m'], df_m['memory_mb'], 'o-', linewidth=2, markersize=8, color='#9b59b6', label='IVFPQ')\n",
        "ax2.axhline(y=flat_memory, color='#e74c3c', linestyle='--', linewidth=2, label='IVFFlat')\n",
        "ax2.set_xlabel('m (subquantizers)')\n",
        "ax2.set_ylabel('Memory (MB)')\n",
        "ax2.set_title('Memory Usage vs m')\n",
        "ax2.set_xscale('log', base=2)\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Search time vs m\n",
        "ax3 = axes[1, 0]\n",
        "ax3.plot(df_m['m'], df_m['search_time_ms'], 'o-', linewidth=2, markersize=8, color='#e74c3c')\n",
        "ax3.set_xlabel('m (subquantizers)')\n",
        "ax3.set_ylabel('Search Time (ms)')\n",
        "ax3.set_title('Search Time vs m')\n",
        "ax3.set_xscale('log', base=2)\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Compression ratio vs recall\n",
        "ax4 = axes[1, 1]\n",
        "compression_ratio = (d * 4) / df_m['bytes_per_vec']\n",
        "ax4.plot(compression_ratio, df_m['recall'], 'o-', linewidth=2, markersize=8, color='#3498db')\n",
        "ax4.set_xlabel('Compression Ratio (original / compressed)')\n",
        "ax4.set_ylabel('Recall@10')\n",
        "ax4.set_title('Recall vs Compression Ratio')\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "# Add annotations\n",
        "for i, (ratio, recall, m) in enumerate(zip(compression_ratio, df_m['recall'], df_m['m'])):\n",
        "    ax4.annotate(f'm={m}', (ratio, recall), textcoords=\"offset points\", xytext=(5, 5), fontsize=9)\n",
        "\n",
        "plt.suptitle(f'Effect of m (nlist={nlist_fixed}, nprobe={nprobe_fixed})', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Experiment 2: Effect of nlist (Number of Clusters)\n",
        "\n",
        "Same as IVFFlat, nlist controls the coarse partitioning:\n",
        "- Higher nlist → Faster search (fewer vectors per cluster)\n",
        "- Lower nlist → Better recall (less boundary effects)\n",
        "- Requires more training data with higher nlist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test different values of nlist\n",
        "nlist_values = [32, 64, 128, 256, 512, 1024]\n",
        "m_fixed = 16\n",
        "nprobe_fixed = 16\n",
        "\n",
        "results_nlist = []\n",
        "\n",
        "print(\"Experiment 2: Varying nlist\")\n",
        "print(f\"Fixed: m={m_fixed}, nprobe={nprobe_fixed}\\n\")\n",
        "print(f\"{'nlist':>8} {'Train(s)':>10} {'Add(s)':>8} {'Search(ms)':>12} {'Recall':>10} {'Vecs/List':>12}\")\n",
        "print(\"-\" * 66)\n",
        "\n",
        "for nlist in nlist_values:\n",
        "    # Build index\n",
        "    index, train_time, add_time = build_ivfpq_index(xb, nlist, m_fixed)\n",
        "    \n",
        "    # Search\n",
        "    distances, labels, search_time = search_ivfpq_index(index, xq, k, nprobe_fixed)\n",
        "    \n",
        "    # Compute metrics\n",
        "    recall = compute_recall(labels_gt, labels, k)\n",
        "    vecs_per_list = nb / nlist\n",
        "    \n",
        "    results_nlist.append({\n",
        "        'nlist': nlist,\n",
        "        'train_time': train_time,\n",
        "        'add_time': add_time,\n",
        "        'search_time_ms': search_time * 1000,\n",
        "        'recall': recall,\n",
        "        'vecs_per_list': vecs_per_list\n",
        "    })\n",
        "    \n",
        "    print(f\"{nlist:>8} {train_time:>10.2f} {add_time:>8.2f} {search_time*1000:>12.2f} {recall:>10.4f} {vecs_per_list:>12.0f}\")\n",
        "\n",
        "df_nlist = pd.DataFrame(results_nlist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize effect of nlist\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Recall vs nlist\n",
        "ax1 = axes[0, 0]\n",
        "ax1.plot(df_nlist['nlist'], df_nlist['recall'], 'o-', linewidth=2, markersize=8, color='#2ecc71')\n",
        "ax1.set_xlabel('nlist (clusters)')\n",
        "ax1.set_ylabel('Recall@10')\n",
        "ax1.set_title('Recall vs nlist')\n",
        "ax1.set_xscale('log', base=2)\n",
        "ax1.set_ylim([0, 1.02])\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Search time vs nlist\n",
        "ax2 = axes[0, 1]\n",
        "ax2.plot(df_nlist['nlist'], df_nlist['search_time_ms'], 'o-', linewidth=2, markersize=8, color='#e74c3c')\n",
        "ax2.set_xlabel('nlist (clusters)')\n",
        "ax2.set_ylabel('Search Time (ms)')\n",
        "ax2.set_title('Search Time vs nlist')\n",
        "ax2.set_xscale('log', base=2)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Train time vs nlist\n",
        "ax3 = axes[1, 0]\n",
        "ax3.plot(df_nlist['nlist'], df_nlist['train_time'], 'o-', linewidth=2, markersize=8, color='#3498db')\n",
        "ax3.set_xlabel('nlist (clusters)')\n",
        "ax3.set_ylabel('Training Time (s)')\n",
        "ax3.set_title('Training Time vs nlist')\n",
        "ax3.set_xscale('log', base=2)\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Vectors per list\n",
        "ax4 = axes[1, 1]\n",
        "ax4.plot(df_nlist['nlist'], df_nlist['vecs_per_list'], 'o-', linewidth=2, markersize=8, color='#9b59b6')\n",
        "ax4.set_xlabel('nlist (clusters)')\n",
        "ax4.set_ylabel('Vectors per List')\n",
        "ax4.set_title('Average Cluster Size vs nlist')\n",
        "ax4.set_xscale('log', base=2)\n",
        "ax4.set_yscale('log')\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle(f'Effect of nlist (m={m_fixed}, nprobe={nprobe_fixed})', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Experiment 3: Effect of nprobe (Search-time Parameter)\n",
        "\n",
        "nprobe is the main search-time parameter:\n",
        "- Higher nprobe → Better recall but slower search\n",
        "- Can be adjusted at query time without rebuilding index\n",
        "- Same trade-off as IVFFlat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test different values of nprobe\n",
        "nprobe_values = [1, 2, 4, 8, 16, 32, 64, 128, 256]\n",
        "nlist_fixed = 256\n",
        "m_fixed = 16\n",
        "\n",
        "# Build index once\n",
        "print(f\"Building index with nlist={nlist_fixed}, m={m_fixed}...\")\n",
        "index, train_time, add_time = build_ivfpq_index(xb, nlist_fixed, m_fixed)\n",
        "print(f\"Index trained in {train_time:.2f}s, vectors added in {add_time:.2f}s\\n\")\n",
        "\n",
        "results_nprobe = []\n",
        "\n",
        "print(\"Experiment 3: Varying nprobe\")\n",
        "print(f\"{'nprobe':>8} {'Search(ms)':>12} {'Recall':>10} {'QPS':>12} {'% Lists':>10}\")\n",
        "print(\"-\" * 56)\n",
        "\n",
        "for nprobe in nprobe_values:\n",
        "    if nprobe > nlist_fixed:\n",
        "        continue\n",
        "        \n",
        "    # Search\n",
        "    distances, labels, search_time = search_ivfpq_index(index, xq, k, nprobe)\n",
        "    \n",
        "    # Compute metrics\n",
        "    recall = compute_recall(labels_gt, labels, k)\n",
        "    qps = nq / search_time\n",
        "    pct_lists = (nprobe / nlist_fixed) * 100\n",
        "    \n",
        "    results_nprobe.append({\n",
        "        'nprobe': nprobe,\n",
        "        'search_time_ms': search_time * 1000,\n",
        "        'recall': recall,\n",
        "        'qps': qps,\n",
        "        'pct_lists': pct_lists\n",
        "    })\n",
        "    \n",
        "    print(f\"{nprobe:>8} {search_time*1000:>12.2f} {recall:>10.4f} {qps:>12.0f} {pct_lists:>10.1f}%\")\n",
        "\n",
        "df_nprobe = pd.DataFrame(results_nprobe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize effect of nprobe\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Recall vs nprobe\n",
        "ax1 = axes[0]\n",
        "ax1.plot(df_nprobe['nprobe'], df_nprobe['recall'], 'o-', linewidth=2, markersize=8, color='#2ecc71')\n",
        "ax1.set_xlabel('nprobe')\n",
        "ax1.set_ylabel('Recall@10')\n",
        "ax1.set_title('Recall vs nprobe')\n",
        "ax1.set_xscale('log', base=2)\n",
        "ax1.set_ylim([0, 1.02])\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Search time vs nprobe\n",
        "ax2 = axes[1]\n",
        "ax2.plot(df_nprobe['nprobe'], df_nprobe['search_time_ms'], 'o-', linewidth=2, markersize=8, color='#e74c3c')\n",
        "ax2.set_xlabel('nprobe')\n",
        "ax2.set_ylabel('Search Time (ms)')\n",
        "ax2.set_title('Search Time vs nprobe')\n",
        "ax2.set_xscale('log', base=2)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# QPS vs nprobe\n",
        "ax3 = axes[2]\n",
        "ax3.plot(df_nprobe['nprobe'], df_nprobe['qps'], 'o-', linewidth=2, markersize=8, color='#3498db')\n",
        "ax3.set_xlabel('nprobe')\n",
        "ax3.set_ylabel('Queries Per Second')\n",
        "ax3.set_title('Throughput vs nprobe')\n",
        "ax3.set_xscale('log', base=2)\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle(f'Effect of nprobe (nlist={nlist_fixed}, m={m_fixed})', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Recall-QPS trade-off curve (Pareto frontier)\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "ax.plot(df_nprobe['recall'], df_nprobe['qps'], 'o-', linewidth=2, markersize=10, color='#8e44ad')\n",
        "\n",
        "# Annotate points with nprobe values\n",
        "for i, row in df_nprobe.iterrows():\n",
        "    ax.annotate(f\"nprobe={int(row['nprobe'])}\", \n",
        "                (row['recall'], row['qps']),\n",
        "                textcoords=\"offset points\", \n",
        "                xytext=(5, 5), \n",
        "                fontsize=9)\n",
        "\n",
        "ax.set_xlabel('Recall@10', fontsize=12)\n",
        "ax.set_ylabel('Queries Per Second (QPS)', fontsize=12)\n",
        "ax.set_title('Recall vs Throughput Trade-off\\n(Pareto Frontier for nprobe)', fontsize=14, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Experiment 4: Combined Grid Search (m × nprobe)\n",
        "\n",
        "Let's explore how m and nprobe interact at search time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Grid search over m and nprobe\n",
        "m_grid = [8, 16, 32, 64]\n",
        "nprobe_grid = [4, 8, 16, 32, 64]\n",
        "nlist_fixed = 256\n",
        "\n",
        "# Pre-build indexes for each m\n",
        "indexes = {}\n",
        "print(\"Building indexes...\")\n",
        "for m in m_grid:\n",
        "    index, train_time, add_time = build_ivfpq_index(xb, nlist_fixed, m)\n",
        "    indexes[m] = index\n",
        "    print(f\"  m={m}: trained in {train_time:.2f}s, added in {add_time:.2f}s\")\n",
        "\n",
        "# Run grid search\n",
        "grid_results = []\n",
        "\n",
        "print(\"\\nRunning grid search...\")\n",
        "for m in m_grid:\n",
        "    index = indexes[m]\n",
        "    for nprobe in nprobe_grid:\n",
        "        distances, labels, search_time = search_ivfpq_index(index, xq, k, nprobe)\n",
        "        recall = compute_recall(labels_gt, labels, k)\n",
        "        qps = nq / search_time\n",
        "        memory = estimate_memory_usage_ivfpq(nb, d, nlist_fixed, m)\n",
        "        \n",
        "        grid_results.append({\n",
        "            'm': m,\n",
        "            'nprobe': nprobe,\n",
        "            'recall': recall,\n",
        "            'search_time_ms': search_time * 1000,\n",
        "            'qps': qps,\n",
        "            'memory_mb': memory\n",
        "        })\n",
        "\n",
        "df_grid = pd.DataFrame(grid_results)\n",
        "print(\"Grid search complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize grid results\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "colors = plt.cm.viridis(np.linspace(0, 1, len(m_grid)))\n",
        "\n",
        "# Recall curves for different m\n",
        "ax1 = axes[0]\n",
        "for i, m in enumerate(m_grid):\n",
        "    data = df_grid[df_grid['m'] == m]\n",
        "    ax1.plot(data['nprobe'], data['recall'], 'o-', \n",
        "             linewidth=2, markersize=8, color=colors[i], label=f'm={m}')\n",
        "ax1.set_xlabel('nprobe')\n",
        "ax1.set_ylabel('Recall@10')\n",
        "ax1.set_title('Recall vs nprobe for Different m')\n",
        "ax1.set_xscale('log', base=2)\n",
        "ax1.set_ylim([0, 1.02])\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Recall vs QPS for different m\n",
        "ax2 = axes[1]\n",
        "for i, m in enumerate(m_grid):\n",
        "    data = df_grid[df_grid['m'] == m]\n",
        "    ax2.plot(data['recall'], data['qps'], 'o-', \n",
        "             linewidth=2, markersize=8, color=colors[i], label=f'm={m}')\n",
        "ax2.set_xlabel('Recall@10')\n",
        "ax2.set_ylabel('Queries Per Second')\n",
        "ax2.set_title('Recall-Throughput Trade-off')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle(f'Combined Effect of m and nprobe (nlist={nlist_fixed})', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Heatmaps for grid search results\n",
        "pivot_recall = df_grid.pivot(index='m', columns='nprobe', values='recall')\n",
        "pivot_qps = df_grid.pivot(index='m', columns='nprobe', values='qps')\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Recall heatmap\n",
        "im1 = axes[0].imshow(pivot_recall.values, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1.0)\n",
        "axes[0].set_xticks(range(len(nprobe_grid)))\n",
        "axes[0].set_xticklabels(nprobe_grid)\n",
        "axes[0].set_yticks(range(len(m_grid)))\n",
        "axes[0].set_yticklabels(m_grid)\n",
        "axes[0].set_xlabel('nprobe')\n",
        "axes[0].set_ylabel('m')\n",
        "axes[0].set_title('Recall@10 Heatmap')\n",
        "\n",
        "# Add text annotations\n",
        "for i in range(len(m_grid)):\n",
        "    for j in range(len(nprobe_grid)):\n",
        "        val = pivot_recall.values[i, j]\n",
        "        axes[0].text(j, i, f'{val:.3f}', ha='center', va='center', color='black', fontsize=10)\n",
        "\n",
        "fig.colorbar(im1, ax=axes[0])\n",
        "\n",
        "# QPS heatmap\n",
        "im2 = axes[1].imshow(pivot_qps.values, cmap='YlOrRd_r', aspect='auto')\n",
        "axes[1].set_xticks(range(len(nprobe_grid)))\n",
        "axes[1].set_xticklabels(nprobe_grid)\n",
        "axes[1].set_yticks(range(len(m_grid)))\n",
        "axes[1].set_yticklabels(m_grid)\n",
        "axes[1].set_xlabel('nprobe')\n",
        "axes[1].set_ylabel('m')\n",
        "axes[1].set_title('QPS Heatmap')\n",
        "\n",
        "# Add text annotations\n",
        "for i in range(len(m_grid)):\n",
        "    for j in range(len(nprobe_grid)):\n",
        "        val = pivot_qps.values[i, j]\n",
        "        axes[1].text(j, i, f'{val:.0f}', ha='center', va='center', color='black', fontsize=10)\n",
        "\n",
        "fig.colorbar(im2, ax=axes[1])\n",
        "\n",
        "plt.suptitle('Parameter Grid Search Results (m × nprobe)', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Experiment 5: IVFPQ vs IVFFlat Comparison\n",
        "\n",
        "Let's compare IVFPQ with IVFFlat to understand the memory-accuracy trade-off."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare IVFPQ with IVFFlat and Brute Force\n",
        "print(\"Comparing IVFPQ with IVFFlat and Brute Force\\n\")\n",
        "\n",
        "# Brute force baseline\n",
        "index_flat = faiss.IndexFlatL2(d)\n",
        "index_flat.add(xb)\n",
        "start = time.time()\n",
        "D_flat, I_flat = index_flat.search(xq, k)\n",
        "flat_search_time = time.time() - start\n",
        "flat_qps = nq / flat_search_time\n",
        "flat_memory = d * nb * 4 / (1024 * 1024)\n",
        "\n",
        "# IVFFlat\n",
        "nlist_test = 256\n",
        "quantizer_ivf = faiss.IndexFlatL2(d)\n",
        "index_ivfflat = faiss.IndexIVFFlat(quantizer_ivf, d, nlist_test)\n",
        "index_ivfflat.train(xb)\n",
        "index_ivfflat.add(xb)\n",
        "index_ivfflat.nprobe = 16\n",
        "start = time.time()\n",
        "D_ivfflat, I_ivfflat = index_ivfflat.search(xq, k)\n",
        "ivfflat_search_time = time.time() - start\n",
        "ivfflat_recall = compute_recall(I_flat, I_ivfflat, k)\n",
        "ivfflat_qps = nq / ivfflat_search_time\n",
        "ivfflat_memory = estimate_memory_usage_flat(nb, d)\n",
        "\n",
        "# IVFPQ with different m values\n",
        "comparison_results = [\n",
        "    {'Method': 'Brute Force', 'Recall': 1.0, 'QPS': flat_qps, 'Memory (MB)': flat_memory},\n",
        "    {'Method': 'IVFFlat', 'Recall': ivfflat_recall, 'QPS': ivfflat_qps, 'Memory (MB)': ivfflat_memory},\n",
        "]\n",
        "\n",
        "for m in [8, 16, 32, 64]:\n",
        "    index_ivfpq, _, _ = build_ivfpq_index(xb, nlist_test, m)\n",
        "    index_ivfpq.nprobe = 16\n",
        "    start = time.time()\n",
        "    D_ivfpq, I_ivfpq = index_ivfpq.search(xq, k)\n",
        "    ivfpq_search_time = time.time() - start\n",
        "    ivfpq_recall = compute_recall(I_flat, I_ivfpq, k)\n",
        "    ivfpq_qps = nq / ivfpq_search_time\n",
        "    ivfpq_memory = estimate_memory_usage_ivfpq(nb, d, nlist_test, m)\n",
        "    \n",
        "    comparison_results.append({\n",
        "        'Method': f'IVFPQ (m={m})',\n",
        "        'Recall': ivfpq_recall,\n",
        "        'QPS': ivfpq_qps,\n",
        "        'Memory (MB)': ivfpq_memory\n",
        "    })\n",
        "\n",
        "df_comparison = pd.DataFrame(comparison_results)\n",
        "print(df_comparison.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize comparison\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "methods = df_comparison['Method'].tolist()\n",
        "colors = ['#3498db', '#2ecc71', '#e74c3c', '#f39c12', '#9b59b6', '#1abc9c']\n",
        "\n",
        "# Memory comparison (bar chart)\n",
        "ax1 = axes[0]\n",
        "bars = ax1.bar(range(len(methods)), df_comparison['Memory (MB)'], color=colors[:len(methods)], edgecolor='black')\n",
        "ax1.set_xticks(range(len(methods)))\n",
        "ax1.set_xticklabels(methods, rotation=45, ha='right')\n",
        "ax1.set_ylabel('Memory (MB)')\n",
        "ax1.set_title('Memory Usage Comparison')\n",
        "for i, v in enumerate(df_comparison['Memory (MB)']):\n",
        "    ax1.text(i, v + 1, f'{v:.1f}', ha='center', fontsize=9)\n",
        "\n",
        "# Recall comparison\n",
        "ax2 = axes[1]\n",
        "bars = ax2.bar(range(len(methods)), df_comparison['Recall'], color=colors[:len(methods)], edgecolor='black')\n",
        "ax2.set_xticks(range(len(methods)))\n",
        "ax2.set_xticklabels(methods, rotation=45, ha='right')\n",
        "ax2.set_ylabel('Recall@10')\n",
        "ax2.set_title('Recall Comparison')\n",
        "ax2.set_ylim([0, 1.1])\n",
        "for i, v in enumerate(df_comparison['Recall']):\n",
        "    ax2.text(i, v + 0.02, f'{v:.3f}', ha='center', fontsize=9)\n",
        "\n",
        "# QPS comparison\n",
        "ax3 = axes[2]\n",
        "bars = ax3.bar(range(len(methods)), df_comparison['QPS'], color=colors[:len(methods)], edgecolor='black')\n",
        "ax3.set_xticks(range(len(methods)))\n",
        "ax3.set_xticklabels(methods, rotation=45, ha='right')\n",
        "ax3.set_ylabel('Queries Per Second')\n",
        "ax3.set_title('Search Speed Comparison')\n",
        "for i, v in enumerate(df_comparison['QPS']):\n",
        "    ax3.text(i, v + 100, f'{v:.0f}', ha='center', fontsize=9)\n",
        "\n",
        "plt.suptitle('IVFPQ vs IVFFlat vs Brute Force (nlist=256, nprobe=16)', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Memory-Recall trade-off scatter plot\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "scatter = ax.scatter(df_comparison['Memory (MB)'], df_comparison['Recall'],\n",
        "                     s=df_comparison['QPS'] / 50,  # Size based on QPS\n",
        "                     c=range(len(df_comparison)),\n",
        "                     cmap='tab10', alpha=0.7, edgecolors='black', linewidth=2)\n",
        "\n",
        "# Add labels\n",
        "for i, row in df_comparison.iterrows():\n",
        "    ax.annotate(row['Method'], \n",
        "                (row['Memory (MB)'], row['Recall']),\n",
        "                textcoords=\"offset points\",\n",
        "                xytext=(10, 5),\n",
        "                fontsize=9,\n",
        "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7))\n",
        "\n",
        "ax.set_xlabel('Memory (MB)', fontsize=12)\n",
        "ax.set_ylabel('Recall@10', fontsize=12)\n",
        "ax.set_title('Memory vs Recall Trade-off\\n(Bubble size = QPS)', fontsize=14, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print compression ratios\n",
        "print(\"\\nCompression ratios vs IVFFlat:\")\n",
        "for _, row in df_comparison.iterrows():\n",
        "    if 'IVFPQ' in row['Method']:\n",
        "        ratio = ivfflat_memory / row['Memory (MB)']\n",
        "        print(f\"  {row['Method']}: {ratio:.1f}x smaller, recall={row['Recall']:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Experiment 6: Typical Configuration Examples\n",
        "\n",
        "Let's test some commonly recommended configurations for different use cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Typical configurations for different use cases\n",
        "configs = [\n",
        "    {'name': 'High compression', 'nlist': 256, 'm': 8, 'nprobe': 8},\n",
        "    {'name': 'Balanced (memory)', 'nlist': 256, 'm': 16, 'nprobe': 16},\n",
        "    {'name': 'Balanced (recall)', 'nlist': 128, 'm': 32, 'nprobe': 16},\n",
        "    {'name': 'High recall', 'nlist': 100, 'm': 64, 'nprobe': 32},\n",
        "    {'name': 'Speed optimized', 'nlist': 1024, 'm': 16, 'nprobe': 8},\n",
        "]\n",
        "\n",
        "config_results = []\n",
        "\n",
        "print(\"Experiment 6: Typical Configuration Examples\\n\")\n",
        "print(f\"{'Config':>20} {'nlist':>6} {'m':>4} {'nprobe':>7} {'Train(s)':>10} {'Search(ms)':>12} {'Recall':>8} {'Mem(MB)':>10}\")\n",
        "print(\"-\" * 90)\n",
        "\n",
        "for config in configs:\n",
        "    # Build index\n",
        "    index, train_time, add_time = build_ivfpq_index(xb, config['nlist'], config['m'])\n",
        "    \n",
        "    # Search\n",
        "    distances, labels, search_time = search_ivfpq_index(index, xq, k, config['nprobe'])\n",
        "    \n",
        "    # Compute metrics\n",
        "    recall = compute_recall(labels_gt, labels, k)\n",
        "    qps = nq / search_time\n",
        "    memory = estimate_memory_usage_ivfpq(nb, d, config['nlist'], config['m'])\n",
        "    \n",
        "    config_results.append({\n",
        "        'name': config['name'],\n",
        "        'nlist': config['nlist'],\n",
        "        'm': config['m'],\n",
        "        'nprobe': config['nprobe'],\n",
        "        'train_time': train_time,\n",
        "        'search_time_ms': search_time * 1000,\n",
        "        'recall': recall,\n",
        "        'qps': qps,\n",
        "        'memory_mb': memory\n",
        "    })\n",
        "    \n",
        "    print(f\"{config['name']:>20} {config['nlist']:>6} {config['m']:>4} {config['nprobe']:>7} \"\n",
        "          f\"{train_time:>10.2f} {search_time*1000:>12.2f} {recall:>8.4f} {memory:>10.1f}\")\n",
        "\n",
        "df_configs = pd.DataFrame(config_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize configurations\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "\n",
        "# Scatter plot: recall vs memory, color by QPS\n",
        "scatter = ax.scatter(df_configs['memory_mb'], df_configs['recall'],\n",
        "                     s=df_configs['qps'] / 30,  # Size based on QPS\n",
        "                     c=df_configs['m'],  # Color based on m\n",
        "                     cmap='coolwarm', alpha=0.7, edgecolors='black', linewidth=2)\n",
        "\n",
        "# Add labels\n",
        "for i, row in df_configs.iterrows():\n",
        "    ax.annotate(f\"{row['name']}\\nnlist={row['nlist']}, m={row['m']}, nprobe={row['nprobe']}\",\n",
        "                (row['memory_mb'], row['recall']),\n",
        "                textcoords=\"offset points\",\n",
        "                xytext=(10, 5),\n",
        "                fontsize=9,\n",
        "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7))\n",
        "\n",
        "ax.set_xlabel('Memory (MB)', fontsize=12)\n",
        "ax.set_ylabel('Recall@10', fontsize=12)\n",
        "ax.set_title('Typical IVFPQ Configurations\\n(Size = QPS, Color = m)', fontsize=14, fontweight='bold')\n",
        "\n",
        "cbar = plt.colorbar(scatter)\n",
        "cbar.set_label('m (subquantizers)', fontsize=11)\n",
        "\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Summary and Recommendations\n",
        "\n",
        "Based on our experiments, here are the key findings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"IVFPQ Parameter Tuning Guidelines\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\"\"\n",
        "INDEX CREATION PARAMETERS:\n",
        "\n",
        "1. m (Number of subquantizers):\n",
        "   - Higher m → Better accuracy, more memory\n",
        "   - Must divide dimension d (here d={d})\n",
        "   - Typical values: 8, 16, 32, 64\n",
        "   - With nbits=8: each vector uses m bytes\n",
        "   - Compression ratio = (d * 4 bytes) / m bytes = {d*4}/m\n",
        "   \n",
        "   Recommended m values for different needs:\n",
        "   - High compression (16-32x): m = 4-8\n",
        "   - Balanced: m = 16-32\n",
        "   - High accuracy: m = 64 or more\n",
        "\n",
        "2. nlist (Number of clusters):\n",
        "   - Same guidelines as IVFFlat\n",
        "   - Rule of thumb: sqrt(n) where n = database size\n",
        "   - For {nb:,} vectors: sqrt({nb}) ≈ {int(np.sqrt(nb))}\n",
        "\n",
        "3. nbits (Bits per subquantizer):\n",
        "   - Usually 8 (256 centroids per subspace)\n",
        "   - Can be 4 for extreme compression (but lower accuracy)\n",
        "\n",
        "SEARCH-TIME PARAMETERS:\n",
        "\n",
        "4. nprobe (Clusters to search):\n",
        "   - Main recall/speed trade-off\n",
        "   - Can be adjusted without rebuilding\n",
        "   - Typical: 1-10% of nlist\n",
        "\n",
        "Common Configurations:\n",
        "---------------------------------------------------------------\n",
        "| Use Case              | nlist    | m  | nprobe | Compression|\n",
        "|-----------------------|----------|----|---------|-----------:|\n",
        "| High compression      | sqrt(n)  | 8  | 4-8    | 64x        |\n",
        "| Balanced              | sqrt(n)  | 16 | 8-16   | 32x        |\n",
        "| High recall           | sqrt(n)/2| 32 | 16-32  | 16x        |\n",
        "| Very high recall      | sqrt(n)/4| 64 | 32-64  | 8x         |\n",
        "---------------------------------------------------------------\n",
        "\"\"\")\n",
        "\n",
        "# Show best configurations from experiments\n",
        "print(\"\\nBest configurations from our experiments:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Find highest recall configuration\n",
        "best_recall = df_grid.loc[df_grid['recall'].idxmax()]\n",
        "print(f\"Highest recall: m={int(best_recall['m'])}, nprobe={int(best_recall['nprobe'])}\")\n",
        "print(f\"  Recall: {best_recall['recall']:.4f}, QPS: {best_recall['qps']:.0f}\")\n",
        "\n",
        "# Find best QPS with >80% recall\n",
        "good_recall = df_grid[df_grid['recall'] > 0.80].sort_values('qps', ascending=False)\n",
        "if len(good_recall) > 0:\n",
        "    best = good_recall.iloc[0]\n",
        "    print(f\"\\nFastest with >80% recall: m={int(best['m'])}, nprobe={int(best['nprobe'])}\")\n",
        "    print(f\"  Recall: {best['recall']:.4f}, QPS: {best['qps']:.0f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_ivfpq_config(nlist, m, nprobe, xb, xq, labels_gt, k, nbits=8):\n",
        "    \"\"\"\n",
        "    Test a specific IVFPQ configuration and print results.\n",
        "    \"\"\"\n",
        "    d = xb.shape[1]\n",
        "    if d % m != 0:\n",
        "        print(f\"Error: m={m} does not divide d={d}. Valid m values: {[i for i in [1,2,4,8,16,32,64] if d % i == 0]}\")\n",
        "        return None, None, None\n",
        "    \n",
        "    print(f\"Testing IVFPQ with nlist={nlist}, m={m}, nprobe={nprobe}, nbits={nbits}\")\n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    # Build\n",
        "    index, train_time, add_time = build_ivfpq_index(xb, nlist, m, nbits)\n",
        "    print(f\"Training time: {train_time:.2f}s\")\n",
        "    print(f\"Add time: {add_time:.2f}s\")\n",
        "    \n",
        "    # Search\n",
        "    distances, labels, search_time = search_ivfpq_index(index, xq, k, nprobe)\n",
        "    print(f\"Search time: {search_time*1000:.2f}ms for {len(xq)} queries\")\n",
        "    \n",
        "    # Metrics\n",
        "    recall = compute_recall(labels_gt, labels, k)\n",
        "    qps = len(xq) / search_time\n",
        "    memory = estimate_memory_usage_ivfpq(len(xb), d, nlist, m, nbits)\n",
        "    compression = (d * 4) / m\n",
        "    \n",
        "    print(f\"\\nRecall@{k}: {recall:.4f}\")\n",
        "    print(f\"QPS: {qps:.0f}\")\n",
        "    print(f\"Memory: {memory:.1f} MB\")\n",
        "    print(f\"Compression ratio: {compression:.1f}x\")\n",
        "    print(f\"Bytes per vector: {m} (from {d*4} bytes)\")\n",
        "    \n",
        "    return index, recall, qps\n",
        "\n",
        "# Example: Try your own configuration!\n",
        "# Modify these parameters and run the cell\n",
        "my_nlist = 200\n",
        "my_m = 32  # Must divide d=128\n",
        "my_nprobe = 20\n",
        "\n",
        "test_ivfpq_config(my_nlist, my_m, my_nprobe, xb, xq, labels_gt, k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Bonus: Using index_factory String\n",
        "\n",
        "FAISS provides a convenient `index_factory` function that creates indexes from a string description."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Using index_factory for IVFPQ\n",
        "print(\"Creating IVFPQ indexes using index_factory:\\n\")\n",
        "\n",
        "# Different index factory strings\n",
        "# Format: IVF{nlist},PQ{m} or IVF{nlist},PQ{m}x{nbits}\n",
        "factory_strings = [\n",
        "    \"IVF256,PQ8\",       # 256 clusters, PQ with 8 subquantizers\n",
        "    \"IVF256,PQ16\",      # 256 clusters, PQ with 16 subquantizers\n",
        "    \"IVF256,PQ32\",      # 256 clusters, PQ with 32 subquantizers\n",
        "    \"IVF100,PQ16\",      # 100 clusters (for higher recall)\n",
        "]\n",
        "\n",
        "for factory_string in factory_strings:\n",
        "    print(f\"Factory string: '{factory_string}'\")\n",
        "    \n",
        "    # Create index using factory\n",
        "    index = faiss.index_factory(d, factory_string)\n",
        "    \n",
        "    # Train and add\n",
        "    start = time.time()\n",
        "    index.train(xb)\n",
        "    train_time = time.time() - start\n",
        "    \n",
        "    start = time.time()\n",
        "    index.add(xb)\n",
        "    add_time = time.time() - start\n",
        "    \n",
        "    # Search with nprobe=16\n",
        "    index.nprobe = 16\n",
        "    start = time.time()\n",
        "    D, I = index.search(xq, k)\n",
        "    search_time = time.time() - start\n",
        "    \n",
        "    recall = compute_recall(labels_gt, I, k)\n",
        "    \n",
        "    print(f\"  nlist: {index.nlist}, nprobe: {index.nprobe}\")\n",
        "    print(f\"  Train: {train_time:.2f}s, Add: {add_time:.2f}s, Search: {search_time*1000:.2f}ms\")\n",
        "    print(f\"  Recall@10: {recall:.4f}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Bonus: OPQ (Optimized Product Quantization)\n",
        "\n",
        "OPQ applies a rotation to vectors before PQ to improve accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare IVFPQ with OPQ (Optimized Product Quantization)\n",
        "print(\"Comparing IVFPQ with OPQ:\\n\")\n",
        "\n",
        "# Standard IVFPQ\n",
        "index_ivfpq = faiss.index_factory(d, \"IVF256,PQ16\")\n",
        "index_ivfpq.train(xb)\n",
        "index_ivfpq.add(xb)\n",
        "index_ivfpq.nprobe = 16\n",
        "D_ivfpq, I_ivfpq = index_ivfpq.search(xq, k)\n",
        "recall_ivfpq = compute_recall(labels_gt, I_ivfpq, k)\n",
        "\n",
        "# IVFPQ with OPQ preprocessing\n",
        "# OPQ{m} applies a rotation learned to minimize PQ quantization error\n",
        "index_opq = faiss.index_factory(d, \"OPQ16,IVF256,PQ16\")\n",
        "index_opq.train(xb)\n",
        "index_opq.add(xb)\n",
        "# For OPQ index, nprobe is set on the IVF part\n",
        "faiss.downcast_index(index_opq.index).nprobe = 16\n",
        "D_opq, I_opq = index_opq.search(xq, k)\n",
        "recall_opq = compute_recall(labels_gt, I_opq, k)\n",
        "\n",
        "print(f\"IVFPQ (IVF256,PQ16):\")\n",
        "print(f\"  Recall@10: {recall_ivfpq:.4f}\")\n",
        "\n",
        "print(f\"\\nOPQ+IVFPQ (OPQ16,IVF256,PQ16):\")\n",
        "print(f\"  Recall@10: {recall_opq:.4f}\")\n",
        "\n",
        "print(f\"\\nOPQ improvement: +{(recall_opq - recall_ivfpq)*100:.1f}% recall\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
