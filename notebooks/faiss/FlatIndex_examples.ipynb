{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FlatIndex (Brute-Force Search) Examples in FAISS\n",
        "\n",
        "This notebook demonstrates the FlatIndex (exact nearest neighbor search) in FAISS with different distance metrics.\n",
        "\n",
        "## Overview\n",
        "\n",
        "FlatIndex is the simplest index type in FAISS:\n",
        "- **Exact search**: Returns true nearest neighbors (100% recall)\n",
        "- **No training required**: Just add vectors and search\n",
        "- **O(n×d) search complexity**: Compares query to every database vector\n",
        "- **Best for**: Small datasets, accuracy baselines, or when exact results are required\n",
        "\n",
        "## Distance Metrics Covered\n",
        "\n",
        "1. **L2 (Euclidean)**: `IndexFlatL2` - Standard squared Euclidean distance\n",
        "2. **Inner Product**: `IndexFlatIP` - Dot product (cosine similarity when normalized)\n",
        "3. **L1 (Manhattan)**: Sum of absolute differences\n",
        "4. **Linf (Chebyshev)**: Maximum absolute difference\n",
        "5. **Cosine Similarity**: Inner product with normalized vectors\n",
        "\n",
        "## Key Differences\n",
        "\n",
        "| Metric | Formula | Range | Use Case |\n",
        "|--------|---------|-------|----------|\n",
        "| L2 | Σ(xᵢ - yᵢ)² | [0, ∞) | General purpose, geometric similarity |\n",
        "| Inner Product | Σ(xᵢ × yᵢ) | (-∞, ∞) | Recommendation, when magnitude matters |\n",
        "| Cosine | (x·y)/(‖x‖‖y‖) | [-1, 1] | Text embeddings, semantic similarity |\n",
        "| L1 | Σ\\|xᵢ - yᵢ\\| | [0, ∞) | Sparse data, robust to outliers |\n",
        "| Linf | max\\|xᵢ - yᵢ\\| | [0, ∞) | Worst-case difference |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import faiss\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Circle\n",
        "import pandas as pd\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Plotting style\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 11\n",
        "\n",
        "# Print available metric types\n",
        "print(\"Available FAISS metric types:\")\n",
        "print(f\"  METRIC_L2 = {faiss.METRIC_L2}\")\n",
        "print(f\"  METRIC_INNER_PRODUCT = {faiss.METRIC_INNER_PRODUCT}\")\n",
        "print(f\"  METRIC_L1 = {faiss.METRIC_L1}\")\n",
        "print(f\"  METRIC_Linf = {faiss.METRIC_Linf}\")\n",
        "print(f\"  METRIC_Canberra = {faiss.METRIC_Canberra}\")\n",
        "print(f\"  METRIC_BrayCurtis = {faiss.METRIC_BrayCurtis}\")\n",
        "print(f\"  METRIC_JensenShannon = {faiss.METRIC_JensenShannon}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Dataset Generation\n",
        "\n",
        "We'll create synthetic datasets for our experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_dataset(nb, nq, d):\n",
        "    \"\"\"Generate random database and query vectors.\"\"\"\n",
        "    xb = np.random.random((nb, d)).astype('float32')\n",
        "    xq = np.random.random((nq, d)).astype('float32')\n",
        "    return xb, xq\n",
        "\n",
        "def normalize_vectors(x):\n",
        "    \"\"\"L2 normalize vectors for cosine similarity.\"\"\"\n",
        "    norms = np.linalg.norm(x, axis=1, keepdims=True)\n",
        "    return (x / norms).astype('float32')\n",
        "\n",
        "# Dataset parameters\n",
        "nb = 10000    # Database size\n",
        "nq = 100      # Number of queries\n",
        "d = 128       # Vector dimension\n",
        "k = 10        # Number of nearest neighbors\n",
        "\n",
        "print(f\"Generating dataset: {nb:,} database vectors, {nq:,} queries, dimension {d}\")\n",
        "xb, xq = generate_dataset(nb, nq, d)\n",
        "print(f\"Database shape: {xb.shape}, Query shape: {xq.shape}\")\n",
        "\n",
        "# Create normalized versions for cosine similarity\n",
        "xb_normalized = normalize_vectors(xb)\n",
        "xq_normalized = normalize_vectors(xq)\n",
        "print(f\"\\nNormalized vectors created (L2 norm = 1.0)\")\n",
        "print(f\"  Sample norm before: {np.linalg.norm(xb[0]):.4f}\")\n",
        "print(f\"  Sample norm after: {np.linalg.norm(xb_normalized[0]):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Basic FlatIndex Usage: L2 vs Inner Product\n",
        "\n",
        "The two most common distance metrics are L2 (Euclidean) and Inner Product."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# IndexFlatL2: Euclidean (L2) distance\n",
        "print(\"=\"*60)\n",
        "print(\"IndexFlatL2 - Euclidean Distance\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "index_l2 = faiss.IndexFlatL2(d)\n",
        "print(f\"Index created: dimension={index_l2.d}, is_trained={index_l2.is_trained}\")\n",
        "\n",
        "# Add vectors (no training needed for Flat index)\n",
        "index_l2.add(xb)\n",
        "print(f\"Vectors added: ntotal={index_l2.ntotal}\")\n",
        "\n",
        "# Search\n",
        "start = time.time()\n",
        "distances_l2, indices_l2 = index_l2.search(xq, k)\n",
        "search_time_l2 = time.time() - start\n",
        "\n",
        "print(f\"\\nSearch completed in {search_time_l2*1000:.2f}ms\")\n",
        "print(f\"QPS: {nq/search_time_l2:.0f}\")\n",
        "\n",
        "# Show sample results\n",
        "print(f\"\\nSample results for query 0:\")\n",
        "print(f\"  Nearest neighbor indices: {indices_l2[0][:5]}\")\n",
        "print(f\"  Squared L2 distances: {distances_l2[0][:5]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# IndexFlatIP: Inner Product (dot product)\n",
        "print(\"=\"*60)\n",
        "print(\"IndexFlatIP - Inner Product\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "index_ip = faiss.IndexFlatIP(d)\n",
        "print(f\"Index created: dimension={index_ip.d}\")\n",
        "\n",
        "# Add vectors\n",
        "index_ip.add(xb)\n",
        "print(f\"Vectors added: ntotal={index_ip.ntotal}\")\n",
        "\n",
        "# Search\n",
        "start = time.time()\n",
        "distances_ip, indices_ip = index_ip.search(xq, k)\n",
        "search_time_ip = time.time() - start\n",
        "\n",
        "print(f\"\\nSearch completed in {search_time_ip*1000:.2f}ms\")\n",
        "print(f\"QPS: {nq/search_time_ip:.0f}\")\n",
        "\n",
        "# Show sample results\n",
        "print(f\"\\nSample results for query 0:\")\n",
        "print(f\"  Nearest neighbor indices: {indices_ip[0][:5]}\")\n",
        "print(f\"  Inner products (higher = more similar): {distances_ip[0][:5]}\")\n",
        "\n",
        "# Note: Inner product returns NEGATIVE distances for max-heap, \n",
        "# but FAISS shows actual inner products (higher is better)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare L2 and IP results\n",
        "print(\"Comparing L2 and Inner Product results:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Check how many neighbors are the same\n",
        "overlap_count = 0\n",
        "for i in range(nq):\n",
        "    l2_set = set(indices_l2[i])\n",
        "    ip_set = set(indices_ip[i])\n",
        "    overlap_count += len(l2_set & ip_set)\n",
        "\n",
        "avg_overlap = overlap_count / nq\n",
        "print(f\"Average overlap in top-{k} neighbors: {avg_overlap:.2f} / {k} ({avg_overlap/k*100:.1f}%)\")\n",
        "\n",
        "# Show example where they differ\n",
        "for i in range(min(5, nq)):\n",
        "    l2_nn = indices_l2[i, 0]\n",
        "    ip_nn = indices_ip[i, 0]\n",
        "    if l2_nn != ip_nn:\n",
        "        print(f\"\\nQuery {i}: L2 nearest = {l2_nn}, IP nearest = {ip_nn}\")\n",
        "        print(f\"  L2 distance to L2-best: {distances_l2[i, 0]:.4f}\")\n",
        "        print(f\"  IP score to IP-best: {distances_ip[i, 0]:.4f}\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Cosine Similarity with Normalized Vectors\n",
        "\n",
        "Cosine similarity can be computed using Inner Product on L2-normalized vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cosine similarity using normalized vectors + Inner Product\n",
        "print(\"=\"*60)\n",
        "print(\"Cosine Similarity (Normalized vectors + Inner Product)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Create index with normalized vectors\n",
        "index_cosine = faiss.IndexFlatIP(d)\n",
        "index_cosine.add(xb_normalized)\n",
        "print(f\"Index created with {index_cosine.ntotal} normalized vectors\")\n",
        "\n",
        "# Search with normalized queries\n",
        "distances_cosine, indices_cosine = index_cosine.search(xq_normalized, k)\n",
        "\n",
        "print(f\"\\nSample results for query 0:\")\n",
        "print(f\"  Nearest neighbor indices: {indices_cosine[0][:5]}\")\n",
        "print(f\"  Cosine similarities (range [-1, 1]): {distances_cosine[0][:5]}\")\n",
        "\n",
        "# Verify cosine similarity calculation\n",
        "q_vec = xq_normalized[0]\n",
        "nn_idx = indices_cosine[0, 0]\n",
        "nn_vec = xb_normalized[nn_idx]\n",
        "manual_cosine = np.dot(q_vec, nn_vec)\n",
        "print(f\"\\n  Manual verification: np.dot(q, nn) = {manual_cosine:.6f}\")\n",
        "print(f\"  FAISS result: {distances_cosine[0, 0]:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Relationship between L2 distance and cosine similarity for normalized vectors\n",
        "print(\"Relationship between L2 and Cosine for normalized vectors:\")\n",
        "print(\"-\" * 60)\n",
        "print(\"For unit vectors: ||x - y||² = 2 - 2*cos(x,y)\")\n",
        "print(\"Therefore: cos(x,y) = 1 - ||x - y||²/2\")\n",
        "print()\n",
        "\n",
        "# Create L2 index with normalized vectors\n",
        "index_l2_norm = faiss.IndexFlatL2(d)\n",
        "index_l2_norm.add(xb_normalized)\n",
        "distances_l2_norm, indices_l2_norm = index_l2_norm.search(xq_normalized, k)\n",
        "\n",
        "# Convert L2 to cosine: cos = 1 - L2²/2\n",
        "cosine_from_l2 = 1 - distances_l2_norm / 2\n",
        "\n",
        "# Compare\n",
        "print(\"For query 0, top-3 neighbors:\")\n",
        "print(f\"{'Index':>6} {'L2 dist':>10} {'Cosine (IP)':>12} {'Cosine (from L2)':>16}\")\n",
        "print(\"-\" * 50)\n",
        "for i in range(3):\n",
        "    idx = indices_l2_norm[0, i]\n",
        "    l2_dist = distances_l2_norm[0, i]\n",
        "    cos_ip = distances_cosine[0, i] if idx == indices_cosine[0, i] else \"N/A\"\n",
        "    cos_l2 = cosine_from_l2[0, i]\n",
        "    print(f\"{idx:>6} {l2_dist:>10.4f} {cos_ip if isinstance(cos_ip, str) else f'{cos_ip:.4f}':>12} {cos_l2:>16.4f}\")\n",
        "\n",
        "# Note: L2 and IP give same ranking for normalized vectors\n",
        "print(f\"\\nL2 neighbors: {indices_l2_norm[0][:5]}\")\n",
        "print(f\"IP neighbors:  {indices_cosine[0][:5]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Other Distance Metrics (L1, Linf, etc.)\n",
        "\n",
        "FAISS supports additional distance metrics through the IndexFlat constructor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# IndexFlat with different metric types\n",
        "metrics = {\n",
        "    'L2': faiss.METRIC_L2,\n",
        "    'Inner Product': faiss.METRIC_INNER_PRODUCT,\n",
        "    'L1 (Manhattan)': faiss.METRIC_L1,\n",
        "    'Linf (Chebyshev)': faiss.METRIC_Linf,\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "print(\"Testing different distance metrics:\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for name, metric in metrics.items():\n",
        "    # Create index with specific metric\n",
        "    index = faiss.IndexFlat(d, metric)\n",
        "    index.add(xb)\n",
        "    \n",
        "    # Search\n",
        "    start = time.time()\n",
        "    distances, indices = index.search(xq, k)\n",
        "    search_time = time.time() - start\n",
        "    \n",
        "    results[name] = {\n",
        "        'distances': distances,\n",
        "        'indices': indices,\n",
        "        'search_time': search_time\n",
        "    }\n",
        "    \n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"  Search time: {search_time*1000:.2f}ms\")\n",
        "    print(f\"  Query 0 - Top 3 neighbors: {indices[0][:3]}\")\n",
        "    print(f\"  Query 0 - Top 3 distances: {distances[0][:3]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Manual verification of distance calculations\n",
        "print(\"Manual verification of distance calculations:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "q = xq[0]\n",
        "nn_l2 = results['L2']['indices'][0, 0]\n",
        "nn_vec = xb[nn_l2]\n",
        "\n",
        "# L2 (squared Euclidean)\n",
        "l2_manual = np.sum((q - nn_vec) ** 2)\n",
        "l2_faiss = results['L2']['distances'][0, 0]\n",
        "print(f\"\\nL2 (squared Euclidean) to nearest neighbor:\")\n",
        "print(f\"  Manual: Σ(xᵢ - yᵢ)² = {l2_manual:.6f}\")\n",
        "print(f\"  FAISS:  {l2_faiss:.6f}\")\n",
        "\n",
        "# Inner Product\n",
        "ip_manual = np.dot(q, nn_vec)\n",
        "nn_ip = results['Inner Product']['indices'][0, 0]\n",
        "ip_faiss = results['Inner Product']['distances'][0, 0]\n",
        "print(f\"\\nInner Product to IP-nearest neighbor (idx={nn_ip}):\")\n",
        "print(f\"  Manual: Σ(xᵢ × yᵢ) = {np.dot(q, xb[nn_ip]):.6f}\")\n",
        "print(f\"  FAISS:  {ip_faiss:.6f}\")\n",
        "\n",
        "# L1 (Manhattan)\n",
        "nn_l1 = results['L1 (Manhattan)']['indices'][0, 0]\n",
        "l1_manual = np.sum(np.abs(q - xb[nn_l1]))\n",
        "l1_faiss = results['L1 (Manhattan)']['distances'][0, 0]\n",
        "print(f\"\\nL1 (Manhattan) to L1-nearest neighbor (idx={nn_l1}):\")\n",
        "print(f\"  Manual: Σ|xᵢ - yᵢ| = {l1_manual:.6f}\")\n",
        "print(f\"  FAISS:  {l1_faiss:.6f}\")\n",
        "\n",
        "# Linf (Chebyshev)\n",
        "nn_linf = results['Linf (Chebyshev)']['indices'][0, 0]\n",
        "linf_manual = np.max(np.abs(q - xb[nn_linf]))\n",
        "linf_faiss = results['Linf (Chebyshev)']['distances'][0, 0]\n",
        "print(f\"\\nLinf (Chebyshev) to Linf-nearest neighbor (idx={nn_linf}):\")\n",
        "print(f\"  Manual: max|xᵢ - yᵢ| = {linf_manual:.6f}\")\n",
        "print(f\"  FAISS:  {linf_faiss:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Visualization: How Different Metrics Rank Neighbors\n",
        "\n",
        "Let's visualize how different distance metrics produce different neighbor rankings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare neighbor rankings across metrics\n",
        "print(\"Neighbor ranking comparison across metrics:\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# For each metric, show top-5 neighbors for query 0\n",
        "metric_names = list(results.keys())\n",
        "query_idx = 0\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for ax, name in zip(axes, metric_names):\n",
        "    indices = results[name]['indices'][query_idx][:10]\n",
        "    distances = results[name]['distances'][query_idx][:10]\n",
        "    \n",
        "    # Create bar chart\n",
        "    colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(indices)))\n",
        "    bars = ax.barh(range(len(indices)), distances, color=colors, edgecolor='black')\n",
        "    ax.set_yticks(range(len(indices)))\n",
        "    ax.set_yticklabels([f\"#{i+1}: idx={idx}\" for i, idx in enumerate(indices)])\n",
        "    ax.invert_yaxis()\n",
        "    \n",
        "    if 'Inner Product' in name:\n",
        "        ax.set_xlabel('Inner Product (higher = more similar)')\n",
        "    else:\n",
        "        ax.set_xlabel('Distance (lower = more similar)')\n",
        "    ax.set_title(f'{name}')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle(f'Top-10 Neighbors for Query {query_idx} by Different Metrics', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Neighbor overlap matrix between metrics\n",
        "print(\"Computing neighbor overlap between different metrics...\")\n",
        "\n",
        "overlap_matrix = np.zeros((len(metric_names), len(metric_names)))\n",
        "\n",
        "for i, name1 in enumerate(metric_names):\n",
        "    for j, name2 in enumerate(metric_names):\n",
        "        total_overlap = 0\n",
        "        for q in range(nq):\n",
        "            set1 = set(results[name1]['indices'][q])\n",
        "            set2 = set(results[name2]['indices'][q])\n",
        "            total_overlap += len(set1 & set2)\n",
        "        overlap_matrix[i, j] = total_overlap / (nq * k) * 100\n",
        "\n",
        "# Plot heatmap\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "im = ax.imshow(overlap_matrix, cmap='YlGn', vmin=0, vmax=100)\n",
        "\n",
        "ax.set_xticks(range(len(metric_names)))\n",
        "ax.set_xticklabels(metric_names, rotation=45, ha='right')\n",
        "ax.set_yticks(range(len(metric_names)))\n",
        "ax.set_yticklabels(metric_names)\n",
        "\n",
        "# Add text annotations\n",
        "for i in range(len(metric_names)):\n",
        "    for j in range(len(metric_names)):\n",
        "        text = ax.text(j, i, f'{overlap_matrix[i, j]:.1f}%',\n",
        "                      ha='center', va='center', color='black', fontsize=11)\n",
        "\n",
        "ax.set_title(f'Top-{k} Neighbor Overlap Between Metrics (%)', fontsize=14, fontweight='bold')\n",
        "fig.colorbar(im, ax=ax, label='Overlap %')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 2D Visualization: Distance Metric Contours\n",
        "\n",
        "Let's visualize what \"equal distance\" looks like for different metrics in 2D."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2D visualization of distance metric contours\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
        "\n",
        "# Create a grid\n",
        "x = np.linspace(-2, 2, 200)\n",
        "y = np.linspace(-2, 2, 200)\n",
        "X, Y = np.meshgrid(x, y)\n",
        "\n",
        "# Origin point\n",
        "origin = np.array([0, 0])\n",
        "\n",
        "# L2 distance\n",
        "ax1 = axes[0, 0]\n",
        "Z_l2 = np.sqrt(X**2 + Y**2)\n",
        "contour1 = ax1.contour(X, Y, Z_l2, levels=[0.5, 1.0, 1.5, 2.0], colors='blue')\n",
        "ax1.clabel(contour1, inline=True, fontsize=10)\n",
        "ax1.plot(0, 0, 'ro', markersize=10, label='Origin')\n",
        "ax1.set_title('L2 (Euclidean) Distance\\nCircular contours', fontsize=12)\n",
        "ax1.set_xlabel('x')\n",
        "ax1.set_ylabel('y')\n",
        "ax1.set_aspect('equal')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.legend()\n",
        "\n",
        "# L1 distance (Manhattan)\n",
        "ax2 = axes[0, 1]\n",
        "Z_l1 = np.abs(X) + np.abs(Y)\n",
        "contour2 = ax2.contour(X, Y, Z_l1, levels=[0.5, 1.0, 1.5, 2.0], colors='green')\n",
        "ax2.clabel(contour2, inline=True, fontsize=10)\n",
        "ax2.plot(0, 0, 'ro', markersize=10, label='Origin')\n",
        "ax2.set_title('L1 (Manhattan) Distance\\nDiamond contours', fontsize=12)\n",
        "ax2.set_xlabel('x')\n",
        "ax2.set_ylabel('y')\n",
        "ax2.set_aspect('equal')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.legend()\n",
        "\n",
        "# Linf distance (Chebyshev)\n",
        "ax3 = axes[1, 0]\n",
        "Z_linf = np.maximum(np.abs(X), np.abs(Y))\n",
        "contour3 = ax3.contour(X, Y, Z_linf, levels=[0.5, 1.0, 1.5, 2.0], colors='purple')\n",
        "ax3.clabel(contour3, inline=True, fontsize=10)\n",
        "ax3.plot(0, 0, 'ro', markersize=10, label='Origin')\n",
        "ax3.set_title('Linf (Chebyshev) Distance\\nSquare contours', fontsize=12)\n",
        "ax3.set_xlabel('x')\n",
        "ax3.set_ylabel('y')\n",
        "ax3.set_aspect('equal')\n",
        "ax3.grid(True, alpha=0.3)\n",
        "ax3.legend()\n",
        "\n",
        "# Inner Product (for reference vector [1, 0])\n",
        "ax4 = axes[1, 1]\n",
        "ref_vec = np.array([1, 0])\n",
        "Z_ip = X * ref_vec[0] + Y * ref_vec[1]  # = X for ref=[1,0]\n",
        "contour4 = ax4.contour(X, Y, Z_ip, levels=[-1, -0.5, 0, 0.5, 1, 1.5], colors='orange')\n",
        "ax4.clabel(contour4, inline=True, fontsize=10)\n",
        "ax4.plot(0, 0, 'ro', markersize=10, label='Origin')\n",
        "ax4.arrow(0, 0, 1, 0, head_width=0.1, head_length=0.05, fc='red', ec='red')\n",
        "ax4.annotate('ref vector', (0.5, 0.15), fontsize=10)\n",
        "ax4.set_title('Inner Product (with ref=[1,0])\\nLinear contours', fontsize=12)\n",
        "ax4.set_xlabel('x')\n",
        "ax4.set_ylabel('y')\n",
        "ax4.set_aspect('equal')\n",
        "ax4.grid(True, alpha=0.3)\n",
        "ax4.legend()\n",
        "\n",
        "plt.suptitle('Distance Metric Contours (Equal distance from origin)', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Performance Comparison Across Metrics\n",
        "\n",
        "Let's compare search speed across different distance metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Performance comparison\n",
        "print(\"Performance Comparison:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Run multiple times for accurate timing\n",
        "n_runs = 5\n",
        "performance_results = []\n",
        "\n",
        "all_metrics = {\n",
        "    'L2 (IndexFlatL2)': (faiss.IndexFlatL2, xb, xq),\n",
        "    'IP (IndexFlatIP)': (faiss.IndexFlatIP, xb, xq),\n",
        "    'Cosine (IP+norm)': (faiss.IndexFlatIP, xb_normalized, xq_normalized),\n",
        "    'L1 (IndexFlat)': (lambda d: faiss.IndexFlat(d, faiss.METRIC_L1), xb, xq),\n",
        "    'Linf (IndexFlat)': (lambda d: faiss.IndexFlat(d, faiss.METRIC_Linf), xb, xq),\n",
        "}\n",
        "\n",
        "for name, (index_class, db, queries) in all_metrics.items():\n",
        "    # Create index\n",
        "    if callable(index_class) and not isinstance(index_class, type):\n",
        "        index = index_class(d)\n",
        "    else:\n",
        "        index = index_class(d)\n",
        "    index.add(db)\n",
        "    \n",
        "    # Warmup\n",
        "    index.search(queries[:10], k)\n",
        "    \n",
        "    # Timed runs\n",
        "    times = []\n",
        "    for _ in range(n_runs):\n",
        "        start = time.time()\n",
        "        index.search(queries, k)\n",
        "        times.append(time.time() - start)\n",
        "    \n",
        "    avg_time = np.mean(times) * 1000\n",
        "    std_time = np.std(times) * 1000\n",
        "    qps = len(queries) / np.mean(times)\n",
        "    \n",
        "    performance_results.append({\n",
        "        'Metric': name,\n",
        "        'Avg Time (ms)': avg_time,\n",
        "        'Std (ms)': std_time,\n",
        "        'QPS': qps\n",
        "    })\n",
        "    \n",
        "    print(f\"{name:>20}: {avg_time:.2f} ± {std_time:.2f} ms ({qps:.0f} QPS)\")\n",
        "\n",
        "df_perf = pd.DataFrame(performance_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize performance\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "colors = plt.cm.Set2(np.linspace(0, 1, len(df_perf)))\n",
        "\n",
        "# Search time comparison\n",
        "ax1 = axes[0]\n",
        "bars1 = ax1.bar(range(len(df_perf)), df_perf['Avg Time (ms)'], \n",
        "                yerr=df_perf['Std (ms)'], capsize=5,\n",
        "                color=colors, edgecolor='black')\n",
        "ax1.set_xticks(range(len(df_perf)))\n",
        "ax1.set_xticklabels(df_perf['Metric'], rotation=45, ha='right')\n",
        "ax1.set_ylabel('Search Time (ms)')\n",
        "ax1.set_title('Search Time by Distance Metric')\n",
        "ax1.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# QPS comparison\n",
        "ax2 = axes[1]\n",
        "bars2 = ax2.bar(range(len(df_perf)), df_perf['QPS'], \n",
        "                color=colors, edgecolor='black')\n",
        "ax2.set_xticks(range(len(df_perf)))\n",
        "ax2.set_xticklabels(df_perf['Metric'], rotation=45, ha='right')\n",
        "ax2.set_ylabel('Queries Per Second')\n",
        "ax2.set_title('Throughput by Distance Metric')\n",
        "ax2.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Add value labels\n",
        "for bar, val in zip(bars2, df_perf['QPS']):\n",
        "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 50,\n",
        "             f'{val:.0f}', ha='center', fontsize=9)\n",
        "\n",
        "plt.suptitle(f'FlatIndex Performance ({nb:,} vectors, {nq} queries)', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Scaling: How FlatIndex Performance Changes with Database Size\n",
        "\n",
        "Since FlatIndex is brute-force, search time scales linearly with database size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scaling experiment\n",
        "db_sizes = [1000, 5000, 10000, 50000, 100000]\n",
        "nq_test = 100\n",
        "d_test = 128\n",
        "k_test = 10\n",
        "\n",
        "scaling_results = []\n",
        "\n",
        "print(\"Scaling experiment: Search time vs database size\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for nb_test in db_sizes:\n",
        "    # Generate data\n",
        "    xb_test = np.random.random((nb_test, d_test)).astype('float32')\n",
        "    xq_test = np.random.random((nq_test, d_test)).astype('float32')\n",
        "    \n",
        "    # Build index\n",
        "    index = faiss.IndexFlatL2(d_test)\n",
        "    \n",
        "    start = time.time()\n",
        "    index.add(xb_test)\n",
        "    add_time = time.time() - start\n",
        "    \n",
        "    # Search (multiple runs)\n",
        "    times = []\n",
        "    for _ in range(3):\n",
        "        start = time.time()\n",
        "        index.search(xq_test, k_test)\n",
        "        times.append(time.time() - start)\n",
        "    \n",
        "    avg_time = np.mean(times) * 1000\n",
        "    qps = nq_test / np.mean(times)\n",
        "    \n",
        "    scaling_results.append({\n",
        "        'db_size': nb_test,\n",
        "        'add_time_ms': add_time * 1000,\n",
        "        'search_time_ms': avg_time,\n",
        "        'qps': qps\n",
        "    })\n",
        "    \n",
        "    print(f\"  {nb_test:>7,} vectors: add={add_time*1000:.1f}ms, search={avg_time:.2f}ms, QPS={qps:.0f}\")\n",
        "\n",
        "df_scaling = pd.DataFrame(scaling_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize scaling\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Search time vs database size\n",
        "ax1 = axes[0]\n",
        "ax1.plot(df_scaling['db_size'], df_scaling['search_time_ms'], 'o-', \n",
        "         linewidth=2, markersize=8, color='#e74c3c')\n",
        "ax1.set_xlabel('Database Size')\n",
        "ax1.set_ylabel('Search Time (ms)')\n",
        "ax1.set_title('Search Time vs Database Size\\n(Linear scaling expected)')\n",
        "ax1.set_xscale('log')\n",
        "ax1.set_yscale('log')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Add linear reference line\n",
        "x_ref = np.array([df_scaling['db_size'].min(), df_scaling['db_size'].max()])\n",
        "y_ref_start = df_scaling['search_time_ms'].iloc[0]\n",
        "y_ref = y_ref_start * (x_ref / x_ref[0])\n",
        "ax1.plot(x_ref, y_ref, '--', color='gray', alpha=0.7, label='Linear reference')\n",
        "ax1.legend()\n",
        "\n",
        "# QPS vs database size\n",
        "ax2 = axes[1]\n",
        "ax2.plot(df_scaling['db_size'], df_scaling['qps'], 'o-', \n",
        "         linewidth=2, markersize=8, color='#3498db')\n",
        "ax2.set_xlabel('Database Size')\n",
        "ax2.set_ylabel('Queries Per Second')\n",
        "ax2.set_title('Throughput vs Database Size\\n(Inverse scaling)')\n",
        "ax2.set_xscale('log')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('FlatIndex Scaling Behavior', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Show scaling factor\n",
        "print(\"\\nScaling analysis:\")\n",
        "print(f\"  10x database size → ~{df_scaling['search_time_ms'].iloc[-1]/df_scaling['search_time_ms'].iloc[0]:.1f}x search time\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. 2D Nearest Neighbor Visualization\n",
        "\n",
        "Let's visualize nearest neighbor search in 2D to understand how different metrics find neighbors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2D nearest neighbor visualization\n",
        "np.random.seed(123)\n",
        "\n",
        "# Create 2D dataset for visualization\n",
        "nb_2d = 200\n",
        "d_2d = 2\n",
        "k_2d = 5\n",
        "\n",
        "# Generate clustered data for interesting visualization\n",
        "xb_2d = np.vstack([\n",
        "    np.random.randn(50, 2) * 0.3 + [1, 1],\n",
        "    np.random.randn(50, 2) * 0.3 + [-1, 1],\n",
        "    np.random.randn(50, 2) * 0.3 + [0, -1],\n",
        "    np.random.randn(100, 2) * 0.8\n",
        "]).astype('float32')\n",
        "\n",
        "# Single query point\n",
        "xq_2d = np.array([[0.0, 0.0]]).astype('float32')\n",
        "\n",
        "# Find neighbors with different metrics\n",
        "metrics_2d = {\n",
        "    'L2': faiss.METRIC_L2,\n",
        "    'L1': faiss.METRIC_L1,\n",
        "    'Linf': faiss.METRIC_Linf,\n",
        "}\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "for ax, (name, metric) in zip(axes, metrics_2d.items()):\n",
        "    # Create index and search\n",
        "    index = faiss.IndexFlat(d_2d, metric)\n",
        "    index.add(xb_2d)\n",
        "    distances, indices = index.search(xq_2d, k_2d)\n",
        "    \n",
        "    # Plot all points\n",
        "    ax.scatter(xb_2d[:, 0], xb_2d[:, 1], c='lightgray', s=30, alpha=0.6, label='Database')\n",
        "    \n",
        "    # Highlight neighbors\n",
        "    nn_points = xb_2d[indices[0]]\n",
        "    ax.scatter(nn_points[:, 0], nn_points[:, 1], c='green', s=100, \n",
        "               edgecolors='black', linewidth=2, label=f'Top-{k_2d} neighbors', zorder=5)\n",
        "    \n",
        "    # Plot query point\n",
        "    ax.scatter(xq_2d[0, 0], xq_2d[0, 1], c='red', s=200, marker='*', \n",
        "               edgecolors='black', linewidth=2, label='Query', zorder=10)\n",
        "    \n",
        "    # Draw lines to neighbors\n",
        "    for i, idx in enumerate(indices[0]):\n",
        "        ax.plot([xq_2d[0, 0], xb_2d[idx, 0]], [xq_2d[0, 1], xb_2d[idx, 1]], \n",
        "                'g--', alpha=0.5, linewidth=1)\n",
        "    \n",
        "    ax.set_title(f'{name} Distance\\nNearest: {indices[0][:3]}')\n",
        "    ax.set_xlabel('x')\n",
        "    ax.set_ylabel('y')\n",
        "    ax.legend(loc='upper right', fontsize=8)\n",
        "    ax.set_aspect('equal')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('2D Nearest Neighbor Search with Different Metrics', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"Practical Use Cases for Each Distance Metric\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "use_cases = \"\"\"\n",
        "L2 (Euclidean) Distance - IndexFlatL2\n",
        "=====================================\n",
        "Best for:\n",
        "  • Image similarity (when using raw pixels or certain embeddings)\n",
        "  • Geographic distance (latitude/longitude after projection)\n",
        "  • General-purpose similarity when magnitude matters\n",
        "  • K-means clustering\n",
        "\n",
        "Characteristics:\n",
        "  • Sensitive to scale differences between dimensions\n",
        "  • Works well when features are normalized/standardized\n",
        "  • Gives circular \"equal distance\" contours\n",
        "\n",
        "\n",
        "Inner Product / Cosine Similarity - IndexFlatIP\n",
        "===============================================\n",
        "Best for:\n",
        "  • Text embeddings (word2vec, BERT, sentence transformers)\n",
        "  • Document similarity\n",
        "  • Recommendation systems\n",
        "  • Any case where direction matters more than magnitude\n",
        "\n",
        "Characteristics:\n",
        "  • Cosine = IP with normalized vectors\n",
        "  • Invariant to vector magnitude (when normalized)\n",
        "  • Linear \"equal distance\" contours\n",
        "  • Returns similarity (higher = more similar), not distance\n",
        "\n",
        "\n",
        "L1 (Manhattan) Distance\n",
        "=======================\n",
        "Best for:\n",
        "  • Sparse data (bag-of-words, TF-IDF)\n",
        "  • When outliers should have less influence\n",
        "  • Grid-based pathfinding\n",
        "\n",
        "Characteristics:\n",
        "  • More robust to outliers than L2\n",
        "  • Diamond-shaped \"equal distance\" contours\n",
        "  • Often faster to compute\n",
        "\n",
        "\n",
        "Linf (Chebyshev) Distance\n",
        "=========================\n",
        "Best for:\n",
        "  • Worst-case analysis\n",
        "  • Games (chessboard distance)\n",
        "  • When any single large difference is important\n",
        "\n",
        "Characteristics:\n",
        "  • Only considers the maximum difference\n",
        "  • Square \"equal distance\" contours\n",
        "  • Good when tolerance in any dimension matters\n",
        "\"\"\"\n",
        "print(use_cases)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Practical Use Cases for Each Metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Using index_factory for FlatIndex\n",
        "\n",
        "FAISS provides a convenient `index_factory` function for creating indexes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Using index_factory for FlatIndex\n",
        "print(\"Creating FlatIndex using index_factory:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "factory_examples = [\n",
        "    (\"Flat\", \"L2 distance (default)\"),\n",
        "    (\"FlatL2\", \"Explicit L2 distance\"),\n",
        "    (\"FlatIP\", \"Inner Product\"),\n",
        "]\n",
        "\n",
        "for factory_str, description in factory_examples:\n",
        "    print(f\"\\n'{factory_str}': {description}\")\n",
        "    \n",
        "    # Create index\n",
        "    index = faiss.index_factory(d, factory_str)\n",
        "    index.add(xb)\n",
        "    \n",
        "    # Search\n",
        "    D, I = index.search(xq[:5], k)\n",
        "    \n",
        "    print(f\"  Created index type: {type(index).__name__}\")\n",
        "    print(f\"  Query 0 - Top 3: {I[0][:3]}, distances: {D[0][:3]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Interactive Parameter Explorer\n",
        "\n",
        "Use this cell to experiment with different distance metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_flat_index(metric_name, xb, xq, k, normalize=False):\n",
        "    \"\"\"\n",
        "    Test FlatIndex with a specific metric.\n",
        "    \n",
        "    Args:\n",
        "        metric_name: 'L2', 'IP', 'L1', 'Linf', or 'Cosine'\n",
        "        xb: Database vectors\n",
        "        xq: Query vectors\n",
        "        k: Number of neighbors\n",
        "        normalize: Whether to L2-normalize vectors (for cosine)\n",
        "    \"\"\"\n",
        "    d = xb.shape[1]\n",
        "    \n",
        "    # Handle normalization for cosine\n",
        "    if normalize or metric_name == 'Cosine':\n",
        "        xb_use = normalize_vectors(xb)\n",
        "        xq_use = normalize_vectors(xq)\n",
        "        metric = faiss.METRIC_INNER_PRODUCT\n",
        "        print(f\"Using normalized vectors for Cosine similarity\")\n",
        "    else:\n",
        "        xb_use = xb\n",
        "        xq_use = xq\n",
        "        metric_map = {\n",
        "            'L2': faiss.METRIC_L2,\n",
        "            'IP': faiss.METRIC_INNER_PRODUCT,\n",
        "            'L1': faiss.METRIC_L1,\n",
        "            'Linf': faiss.METRIC_Linf,\n",
        "        }\n",
        "        metric = metric_map.get(metric_name, faiss.METRIC_L2)\n",
        "    \n",
        "    print(f\"\\nTesting FlatIndex with {metric_name} metric\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    # Create and populate index\n",
        "    index = faiss.IndexFlat(d, metric)\n",
        "    index.add(xb_use)\n",
        "    print(f\"Index: {index.ntotal} vectors, dimension {d}\")\n",
        "    \n",
        "    # Search\n",
        "    start = time.time()\n",
        "    distances, indices = index.search(xq_use, k)\n",
        "    search_time = time.time() - start\n",
        "    \n",
        "    # Results\n",
        "    qps = len(xq) / search_time\n",
        "    print(f\"Search time: {search_time*1000:.2f}ms ({qps:.0f} QPS)\")\n",
        "    print(f\"\\nTop-{k} neighbors for query 0:\")\n",
        "    for i in range(min(5, k)):\n",
        "        print(f\"  #{i+1}: index={indices[0, i]}, distance={distances[0, i]:.4f}\")\n",
        "    \n",
        "    return index, distances, indices\n",
        "\n",
        "# Example: Try different metrics!\n",
        "# Options: 'L2', 'IP', 'L1', 'Linf', 'Cosine'\n",
        "my_metric = 'Cosine'\n",
        "my_k = 10\n",
        "\n",
        "test_flat_index(my_metric, xb, xq, my_k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Summary\n",
        "\n",
        "Key takeaways from this notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"FlatIndex Summary\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "summary = \"\"\"\n",
        "WHEN TO USE FLATINDEX\n",
        "=====================\n",
        "✓ Small datasets (< 100K vectors typically)\n",
        "✓ Need exact/ground truth results\n",
        "✓ Creating baselines for comparison\n",
        "✓ When search time is not critical\n",
        "✓ Index building speed is important (no training needed)\n",
        "\n",
        "WHEN TO AVOID FLATINDEX  \n",
        "========================\n",
        "✗ Large datasets (> 1M vectors)\n",
        "✗ Real-time applications requiring low latency\n",
        "✗ Memory-constrained environments (stores full vectors)\n",
        "\n",
        "DISTANCE METRIC QUICK REFERENCE\n",
        "===============================\n",
        "┌────────────┬──────────────────┬────────────────────────────┐\n",
        "│ Metric     │ FAISS Index      │ Best Use Case              │\n",
        "├────────────┼──────────────────┼────────────────────────────┤\n",
        "│ L2         │ IndexFlatL2      │ General purpose            │\n",
        "│ Cosine     │ IndexFlatIP+norm │ Text/document embeddings   │\n",
        "│ IP         │ IndexFlatIP      │ Recommendations            │\n",
        "│ L1         │ IndexFlat(L1)    │ Sparse data, robustness    │\n",
        "│ Linf       │ IndexFlat(Linf)  │ Worst-case analysis        │\n",
        "└────────────┴──────────────────┴────────────────────────────┘\n",
        "\n",
        "PERFORMANCE NOTES\n",
        "=================\n",
        "• Search time: O(n × d) - linear in database size\n",
        "• Memory: O(n × d × 4) bytes for float32 vectors\n",
        "• No training required - instant index creation\n",
        "• All metrics have similar computational cost\n",
        "\n",
        "For larger datasets, consider:\n",
        "• IVFFlat: Approximate search with inverted file\n",
        "• IVFPQ: Compressed vectors for memory efficiency  \n",
        "• HNSW: Graph-based approximate search\n",
        "\"\"\"\n",
        "print(summary)\n",
        "\n",
        "# Show memory estimate for current dataset\n",
        "memory_mb = nb * d * 4 / (1024 * 1024)\n",
        "print(f\"\\nMemory for current dataset ({nb:,} × {d} float32): {memory_mb:.1f} MB\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
